{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"/home/hasan/Desktop/irish_PyTorch/iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "dataset['species'] = le.fit_transform(dataset[\"species\"])\n",
    "\n",
    "# dataset.species = dfx.sentiment.apply(lambda x: 1 if x == \"Iris-setosa\" 2 if x == \"Iris-versicolor\"  else 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width  species\n",
      "0           6.0          2.7           5.1          1.6        1\n",
      "1           6.3          3.3           6.0          2.5        2\n",
      "2           7.7          3.8           6.7          2.2        2\n",
      "3           6.7          3.1           4.7          1.5        1\n",
      "4           6.4          2.8           5.6          2.2        2\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(['species'], axis=1).values\n",
    "y = dataset['species'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, xtest, Y_train, ytest  = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "Xtrain, xvalid, Ytrain, yvalid = train_test_split(X_train, Y_train, random_state=42, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 4), (30, 4), (12, 4), (108,), (30,), (12,))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape, xtest.shape, xvalid.shape, Ytrain.shape, ytest.shape, yvalid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = torch.FloatTensor(Xtrain)\n",
    "xtest = torch.FloatTensor(xtest)\n",
    "xvalid = torch.FloatTensor(xvalid)\n",
    "Ytrain = torch.LongTensor(Ytrain)\n",
    "ytest = torch.LongTensor(ytest)\n",
    "yvalid = torch.LongTensor(yvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_features=4, hidden_layer1=25, hidden_layer2=30, output_features=3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_features,hidden_layer1)                  \n",
    "        self.fc2 = nn.Linear(hidden_layer1, hidden_layer2)                  \n",
    "        self.out = nn.Linear(hidden_layer2, output_features)      \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining optimizer and criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.SGD(Model.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.Adam(Model.parameters(), lr=0.01)\n",
    "#loss = nn.CrossEntropyLoss()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Train_loss: 1.11030793  Valid_loss:1.10106575 \n",
      "Epoch:  1  Train_loss: 1.03795004  Valid_loss:1.03558552 \n",
      "Epoch:  2  Train_loss: 0.97704440  Valid_loss:0.98087806 \n",
      "Epoch:  3  Train_loss: 0.91900563  Valid_loss:0.92865926 \n",
      "Epoch:  4  Train_loss: 0.86179805  Valid_loss:0.87051225 \n",
      "Epoch:  5  Train_loss: 0.80056810  Valid_loss:0.80145532 \n",
      "Epoch:  6  Train_loss: 0.73985451  Valid_loss:0.73037416 \n",
      "Epoch:  7  Train_loss: 0.67891717  Valid_loss:0.66298062 \n",
      "Epoch:  8  Train_loss: 0.61502534  Valid_loss:0.59677905 \n",
      "Epoch:  9  Train_loss: 0.55678231  Valid_loss:0.53465861 \n",
      "Epoch: 10  Train_loss: 0.50964230  Valid_loss:0.48253047 \n",
      "Epoch: 11  Train_loss: 0.47167602  Valid_loss:0.44252422 \n",
      "Epoch: 12  Train_loss: 0.43643668  Valid_loss:0.40809909 \n",
      "Epoch: 13  Train_loss: 0.40357500  Valid_loss:0.38095474 \n",
      "Epoch: 14  Train_loss: 0.38016322  Valid_loss:0.35948181 \n",
      "Epoch: 15  Train_loss: 0.35978037  Valid_loss:0.33892402 \n",
      "Epoch: 16  Train_loss: 0.34145662  Valid_loss:0.32059580 \n",
      "Epoch: 17  Train_loss: 0.32147270  Valid_loss:0.30409688 \n",
      "Epoch: 18  Train_loss: 0.29996797  Valid_loss:0.28803819 \n",
      "Epoch: 19  Train_loss: 0.27898273  Valid_loss:0.27089182 \n",
      "Epoch: 20  Train_loss: 0.25790811  Valid_loss:0.25224432 \n",
      "Epoch: 21  Train_loss: 0.23787317  Valid_loss:0.23481409 \n",
      "Epoch: 22  Train_loss: 0.21750192  Valid_loss:0.21743838 \n",
      "Epoch: 23  Train_loss: 0.19970436  Valid_loss:0.20083050 \n",
      "Epoch: 24  Train_loss: 0.18320642  Valid_loss:0.18568377 \n",
      "Epoch: 25  Train_loss: 0.16729090  Valid_loss:0.16921711 \n",
      "Epoch: 26  Train_loss: 0.15382706  Valid_loss:0.15454160 \n",
      "Epoch: 27  Train_loss: 0.14108633  Valid_loss:0.14171453 \n",
      "Epoch: 28  Train_loss: 0.13118333  Valid_loss:0.12804250 \n",
      "Epoch: 29  Train_loss: 0.12225523  Valid_loss:0.11606532 \n",
      "Epoch: 30  Train_loss: 0.11382292  Valid_loss:0.10616929 \n",
      "Epoch: 31  Train_loss: 0.10947040  Valid_loss:0.09411168 \n",
      "Epoch: 32  Train_loss: 0.10188948  Valid_loss:0.08673690 \n",
      "Epoch: 33  Train_loss: 0.09911837  Valid_loss:0.07611804 \n",
      "Epoch: 34  Train_loss: 0.09423345  Valid_loss:0.06916653 \n",
      "Epoch: 35  Train_loss: 0.09110869  Valid_loss:0.06195110 \n",
      "Epoch: 36  Train_loss: 0.08953726  Valid_loss:0.05449238 \n",
      "Epoch: 37  Train_loss: 0.08538977  Valid_loss:0.05071897 \n",
      "Epoch: 38  Train_loss: 0.08647255  Valid_loss:0.04272936 \n",
      "Epoch: 39  Train_loss: 0.08139596  Valid_loss:0.04153654 \n",
      "Epoch: 40  Train_loss: 0.08352783  Valid_loss:0.03372789 \n",
      "Epoch: 41  Train_loss: 0.07897362  Valid_loss:0.03283593 \n",
      "Epoch: 42  Train_loss: 0.07932864  Valid_loss:0.02768951 \n",
      "Epoch: 43  Train_loss: 0.07823771  Valid_loss:0.02482804 \n",
      "Epoch: 44  Train_loss: 0.07612685  Valid_loss:0.02369157 \n",
      "Epoch: 45  Train_loss: 0.07754143  Valid_loss:0.01935256 \n",
      "Epoch: 46  Train_loss: 0.07477794  Valid_loss:0.01920692 \n",
      "Epoch: 47  Train_loss: 0.07497517  Valid_loss:0.01643836 \n",
      "Epoch: 48  Train_loss: 0.07472879  Valid_loss:0.01465078 \n",
      "Epoch: 49  Train_loss: 0.07319660  Valid_loss:0.01446393 \n",
      "Epoch: 50  Train_loss: 0.07403633  Valid_loss:0.01194185 \n",
      "Epoch: 51  Train_loss: 0.07269874  Valid_loss:0.01165439 \n",
      "Epoch: 52  Train_loss: 0.07228940  Valid_loss:0.01076655 \n",
      "Epoch: 53  Train_loss: 0.07275961  Valid_loss:0.00924234 \n",
      "Epoch: 54  Train_loss: 0.07151543  Valid_loss:0.00940344 \n",
      "Epoch: 55  Train_loss: 0.07168832  Valid_loss:0.00818990 \n",
      "Epoch: 56  Train_loss: 0.07145489  Valid_loss:0.00758977 \n",
      "Epoch: 57  Train_loss: 0.07076167  Valid_loss:0.00759316 \n",
      "Epoch: 58  Train_loss: 0.07108913  Valid_loss:0.00655432 \n",
      "Epoch: 59  Train_loss: 0.07049891  Valid_loss:0.00645749 \n",
      "Epoch: 60  Train_loss: 0.07022293  Valid_loss:0.00618988 \n",
      "Epoch: 61  Train_loss: 0.07044109  Valid_loss:0.00550377 \n",
      "Epoch: 62  Train_loss: 0.06983232  Valid_loss:0.00561451 \n",
      "Epoch: 63  Train_loss: 0.06982041  Valid_loss:0.00515324 \n",
      "Epoch: 64  Train_loss: 0.06975709  Valid_loss:0.00483685 \n",
      "Epoch: 65  Train_loss: 0.06934364  Valid_loss:0.00490537 \n",
      "Epoch: 66  Train_loss: 0.06944990  Valid_loss:0.00443120 \n",
      "Epoch: 67  Train_loss: 0.06913957  Valid_loss:0.00438879 \n",
      "Epoch: 68  Train_loss: 0.06893447  Valid_loss:0.00429970 \n",
      "Epoch: 69  Train_loss: 0.06900284  Valid_loss:0.00396025 \n",
      "Epoch: 70  Train_loss: 0.06862797  Valid_loss:0.00404698 \n",
      "Epoch: 71  Train_loss: 0.06858686  Valid_loss:0.00380592 \n",
      "Epoch: 72  Train_loss: 0.06845930  Valid_loss:0.00368598 \n",
      "Epoch: 73  Train_loss: 0.06819873  Valid_loss:0.00372169 \n",
      "Epoch: 74  Train_loss: 0.06822306  Valid_loss:0.00346744 \n",
      "Epoch: 75  Train_loss: 0.06793855  Valid_loss:0.00351738 \n",
      "Epoch: 76  Train_loss: 0.06783061  Valid_loss:0.00340637 \n",
      "Epoch: 77  Train_loss: 0.06774879  Valid_loss:0.00329002 \n",
      "Epoch: 78  Train_loss: 0.06749796  Valid_loss:0.00334926 \n",
      "Epoch: 79  Train_loss: 0.06748055  Valid_loss:0.00317135 \n",
      "Epoch: 80  Train_loss: 0.06724440  Valid_loss:0.00321275 \n",
      "Epoch: 81  Train_loss: 0.06712725  Valid_loss:0.00314582 \n",
      "Epoch: 82  Train_loss: 0.06703383  Valid_loss:0.00306719 \n",
      "Epoch: 83  Train_loss: 0.06681355  Valid_loss:0.00312077 \n",
      "Epoch: 84  Train_loss: 0.06678027  Valid_loss:0.00298691 \n",
      "Epoch: 85  Train_loss: 0.06655284  Valid_loss:0.00304707 \n",
      "Epoch: 86  Train_loss: 0.06646822  Valid_loss:0.00296864 \n",
      "Epoch: 87  Train_loss: 0.06632744  Valid_loss:0.00295342 \n",
      "Epoch: 88  Train_loss: 0.06616379  Valid_loss:0.00296756 \n",
      "Epoch: 89  Train_loss: 0.06610291  Valid_loss:0.00288283 \n",
      "Epoch: 90  Train_loss: 0.06589297  Valid_loss:0.00294865 \n",
      "Epoch: 91  Train_loss: 0.06585051  Valid_loss:0.00284799 \n",
      "Epoch: 92  Train_loss: 0.06564884  Valid_loss:0.00290809 \n",
      "Epoch: 93  Train_loss: 0.06558000  Valid_loss:0.00283800 \n",
      "Epoch: 94  Train_loss: 0.06542222  Valid_loss:0.00285999 \n",
      "Epoch: 95  Train_loss: 0.06531271  Valid_loss:0.00283712 \n",
      "Epoch: 96  Train_loss: 0.06520417  Valid_loss:0.00281633 \n",
      "Epoch: 97  Train_loss: 0.06505784  Valid_loss:0.00283614 \n",
      "Epoch: 98  Train_loss: 0.06499153  Valid_loss:0.00277847 \n",
      "Epoch: 99  Train_loss: 0.06481269  Valid_loss:0.00283554 \n",
      "Epoch: 100  Train_loss: 0.06478389  Valid_loss:0.00274483 \n",
      "Epoch: 101  Train_loss: 0.06457377  Valid_loss:0.00283807 \n",
      "Epoch: 102  Train_loss: 0.06459118  Valid_loss:0.00270747 \n",
      "Epoch: 103  Train_loss: 0.06433508  Valid_loss:0.00285633 \n",
      "Epoch: 104  Train_loss: 0.06444453  Valid_loss:0.00265012 \n",
      "Epoch: 105  Train_loss: 0.06410085  Valid_loss:0.00291479 \n",
      "Epoch: 106  Train_loss: 0.06442730  Valid_loss:0.00255047 \n",
      "Epoch: 107  Train_loss: 0.06393712  Valid_loss:0.00306852 \n",
      "Epoch: 108  Train_loss: 0.06483293  Valid_loss:0.00237887 \n",
      "Epoch: 109  Train_loss: 0.06417081  Valid_loss:0.00344268 \n",
      "Epoch: 110  Train_loss: 0.06645373  Valid_loss:0.00215564 \n",
      "Epoch: 111  Train_loss: 0.06520087  Valid_loss:0.00404345 \n",
      "Epoch: 112  Train_loss: 0.06793804  Valid_loss:0.00205457 \n",
      "Epoch: 113  Train_loss: 0.06428535  Valid_loss:0.00369145 \n",
      "Epoch: 114  Train_loss: 0.06383411  Valid_loss:0.00243313 \n",
      "Epoch: 115  Train_loss: 0.06364114  Valid_loss:0.00245857 \n",
      "Epoch: 116  Train_loss: 0.06366641  Valid_loss:0.00347269 \n",
      "Epoch: 117  Train_loss: 0.06568362  Valid_loss:0.00210498 \n",
      "Epoch: 118  Train_loss: 0.06320653  Valid_loss:0.00326451 \n",
      "Epoch: 119  Train_loss: 0.06294615  Valid_loss:0.00260268 \n",
      "Epoch: 120  Train_loss: 0.06361909  Valid_loss:0.00231587 \n",
      "Epoch: 121  Train_loss: 0.06311580  Valid_loss:0.00334567 \n",
      "Epoch: 122  Train_loss: 0.06399949  Valid_loss:0.00220287 \n",
      "Epoch: 123  Train_loss: 0.06249490  Valid_loss:0.00282423 \n",
      "Epoch: 124  Train_loss: 0.06242039  Valid_loss:0.00283411 \n",
      "Epoch: 125  Train_loss: 0.06353420  Valid_loss:0.00221874 \n",
      "Epoch: 126  Train_loss: 0.06248556  Valid_loss:0.00312998 \n",
      "Epoch: 127  Train_loss: 0.06269503  Valid_loss:0.00236965 \n",
      "Epoch: 128  Train_loss: 0.06227963  Valid_loss:0.00252123 \n",
      "Epoch: 129  Train_loss: 0.06210084  Valid_loss:0.00293521 \n",
      "Epoch: 130  Train_loss: 0.06295325  Valid_loss:0.00222359 \n",
      "Epoch: 131  Train_loss: 0.06192615  Valid_loss:0.00287526 \n",
      "Epoch: 132  Train_loss: 0.06195495  Valid_loss:0.00251822 \n",
      "Epoch: 133  Train_loss: 0.06212975  Valid_loss:0.00237675 \n",
      "Epoch: 134  Train_loss: 0.06172974  Valid_loss:0.00289651 \n",
      "Epoch: 135  Train_loss: 0.06224893  Valid_loss:0.00227491 \n",
      "Epoch: 136  Train_loss: 0.06153500  Valid_loss:0.00269031 \n",
      "Epoch: 137  Train_loss: 0.06150527  Valid_loss:0.00258183 \n",
      "Epoch: 138  Train_loss: 0.06180890  Valid_loss:0.00233266 \n",
      "Epoch: 139  Train_loss: 0.06133948  Valid_loss:0.00280528 \n",
      "Epoch: 140  Train_loss: 0.06168587  Valid_loss:0.00231475 \n",
      "Epoch: 141  Train_loss: 0.06120153  Valid_loss:0.00259752 \n",
      "Epoch: 142  Train_loss: 0.06114487  Valid_loss:0.00256814 \n",
      "Epoch: 143  Train_loss: 0.06139011  Valid_loss:0.00233406 \n",
      "Epoch: 144  Train_loss: 0.06097239  Valid_loss:0.00272171 \n",
      "Epoch: 145  Train_loss: 0.06125825  Valid_loss:0.00232125 \n",
      "Epoch: 146  Train_loss: 0.06085477  Valid_loss:0.00257271 \n",
      "Epoch: 147  Train_loss: 0.06082906  Valid_loss:0.00250357 \n",
      "Epoch: 148  Train_loss: 0.06093624  Valid_loss:0.00236402 \n",
      "Epoch: 149  Train_loss: 0.06062599  Valid_loss:0.00264340 \n",
      "Epoch: 150  Train_loss: 0.06088690  Valid_loss:0.00231131 \n",
      "Epoch: 151  Train_loss: 0.06050038  Valid_loss:0.00258411 \n",
      "Epoch: 152  Train_loss: 0.06056450  Valid_loss:0.00241209 \n",
      "Epoch: 153  Train_loss: 0.06047606  Valid_loss:0.00242510 \n",
      "Epoch: 154  Train_loss: 0.06030974  Valid_loss:0.00254349 \n",
      "Epoch: 155  Train_loss: 0.06048510  Valid_loss:0.00232313 \n",
      "Epoch: 156  Train_loss: 0.06015980  Valid_loss:0.00258214 \n",
      "Epoch: 157  Train_loss: 0.06032955  Valid_loss:0.00232796 \n",
      "Epoch: 158  Train_loss: 0.06005248  Valid_loss:0.00251186 \n",
      "Epoch: 159  Train_loss: 0.06007595  Valid_loss:0.00240395 \n",
      "Epoch: 160  Train_loss: 0.06000168  Valid_loss:0.00240803 \n",
      "Epoch: 161  Train_loss: 0.05986509  Valid_loss:0.00248559 \n",
      "Epoch: 162  Train_loss: 0.05996191  Valid_loss:0.00233387 \n",
      "Epoch: 163  Train_loss: 0.05970984  Valid_loss:0.00252656 \n",
      "Epoch: 164  Train_loss: 0.05986269  Valid_loss:0.00230881 \n",
      "Epoch: 165  Train_loss: 0.05958188  Valid_loss:0.00251693 \n",
      "Epoch: 166  Train_loss: 0.05970154  Valid_loss:0.00232225 \n",
      "Epoch: 167  Train_loss: 0.05947130  Valid_loss:0.00247626 \n",
      "Epoch: 168  Train_loss: 0.05952014  Valid_loss:0.00235364 \n",
      "Epoch: 169  Train_loss: 0.05937378  Valid_loss:0.00242880 \n",
      "Epoch: 170  Train_loss: 0.05934708  Valid_loss:0.00238709 \n",
      "Epoch: 171  Train_loss: 0.05928257  Valid_loss:0.00238572 \n",
      "Epoch: 172  Train_loss: 0.05918868  Valid_loss:0.00241556 \n",
      "Epoch: 173  Train_loss: 0.05919182  Valid_loss:0.00234988 \n",
      "Epoch: 174  Train_loss: 0.05904062  Valid_loss:0.00243990 \n",
      "Epoch: 175  Train_loss: 0.05910457  Valid_loss:0.00231653 \n",
      "Epoch: 176  Train_loss: 0.05889630  Valid_loss:0.00246763 \n",
      "Epoch: 177  Train_loss: 0.05903688  Valid_loss:0.00227509 \n",
      "Epoch: 178  Train_loss: 0.05875152  Valid_loss:0.00251507 \n",
      "Epoch: 179  Train_loss: 0.05902737  Valid_loss:0.00221004 \n",
      "Epoch: 180  Train_loss: 0.05862031  Valid_loss:0.00260893 \n",
      "Epoch: 181  Train_loss: 0.05918197  Valid_loss:0.00209777 \n",
      "Epoch: 182  Train_loss: 0.05858932  Valid_loss:0.00280839 \n",
      "Epoch: 183  Train_loss: 0.05982902  Valid_loss:0.00190889 \n",
      "Epoch: 184  Train_loss: 0.05899882  Valid_loss:0.00323377 \n",
      "Epoch: 185  Train_loss: 0.06181135  Valid_loss:0.00165333 \n",
      "Epoch: 186  Train_loss: 0.06037884  Valid_loss:0.00395702 \n",
      "Epoch: 187  Train_loss: 0.06480640  Valid_loss:0.00147981 \n",
      "Epoch: 188  Train_loss: 0.06055305  Valid_loss:0.00407037 \n",
      "Epoch: 189  Train_loss: 0.06124122  Valid_loss:0.00166654 \n",
      "Epoch: 190  Train_loss: 0.05807023  Valid_loss:0.00264553 \n",
      "Epoch: 191  Train_loss: 0.05809932  Valid_loss:0.00278972 \n",
      "Epoch: 192  Train_loss: 0.06090960  Valid_loss:0.00167109 \n",
      "Epoch: 193  Train_loss: 0.05914399  Valid_loss:0.00354740 \n",
      "Epoch: 194  Train_loss: 0.06001116  Valid_loss:0.00175291 \n",
      "Epoch: 195  Train_loss: 0.05781531  Valid_loss:0.00253628 \n",
      "Epoch: 196  Train_loss: 0.05783353  Valid_loss:0.00273900 \n",
      "Epoch: 197  Train_loss: 0.05993000  Valid_loss:0.00173439 \n",
      "Epoch: 198  Train_loss: 0.05826038  Valid_loss:0.00318358 \n",
      "Epoch: 199  Train_loss: 0.05862427  Valid_loss:0.00193771 \n",
      "Epoch: 200  Train_loss: 0.05770333  Valid_loss:0.00229681 \n",
      "Epoch: 201  Train_loss: 0.05764844  Valid_loss:0.00279310 \n",
      "Epoch: 202  Train_loss: 0.05920811  Valid_loss:0.00178856 \n",
      "Epoch: 203  Train_loss: 0.05764529  Valid_loss:0.00288537 \n",
      "Epoch: 204  Train_loss: 0.05778988  Valid_loss:0.00212105 \n",
      "Epoch: 205  Train_loss: 0.05768827  Valid_loss:0.00214590 \n",
      "Epoch: 206  Train_loss: 0.05741353  Valid_loss:0.00277672 \n",
      "Epoch: 207  Train_loss: 0.05847203  Valid_loss:0.00186918 \n",
      "Epoch: 208  Train_loss: 0.05725292  Valid_loss:0.00266277 \n",
      "Epoch: 209  Train_loss: 0.05734209  Valid_loss:0.00224035 \n",
      "Epoch: 210  Train_loss: 0.05755710  Valid_loss:0.00209305 \n",
      "Epoch: 211  Train_loss: 0.05714124  Valid_loss:0.00270271 \n",
      "Epoch: 212  Train_loss: 0.05787892  Valid_loss:0.00194868 \n",
      "Epoch: 213  Train_loss: 0.05699564  Valid_loss:0.00253481 \n",
      "Epoch: 214  Train_loss: 0.05706704  Valid_loss:0.00227835 \n",
      "Epoch: 215  Train_loss: 0.05729091  Valid_loss:0.00210580 \n",
      "Epoch: 216  Train_loss: 0.05687919  Valid_loss:0.00261257 \n",
      "Epoch: 217  Train_loss: 0.05744830  Valid_loss:0.00200572 \n",
      "Epoch: 218  Train_loss: 0.05677608  Valid_loss:0.00248508 \n",
      "Epoch: 219  Train_loss: 0.05686933  Valid_loss:0.00225376 \n",
      "Epoch: 220  Train_loss: 0.05696031  Valid_loss:0.00215849 \n",
      "Epoch: 221  Train_loss: 0.05664413  Valid_loss:0.00252110 \n",
      "Epoch: 222  Train_loss: 0.05711007  Valid_loss:0.00204415 \n",
      "Epoch: 223  Train_loss: 0.05655914  Valid_loss:0.00248163 \n",
      "Epoch: 224  Train_loss: 0.05672875  Valid_loss:0.00219216 \n",
      "Epoch: 225  Train_loss: 0.05661724  Valid_loss:0.00224347 \n",
      "Epoch: 226  Train_loss: 0.05644605  Valid_loss:0.00241439 \n",
      "Epoch: 227  Train_loss: 0.05677411  Valid_loss:0.00209239 \n",
      "Epoch: 228  Train_loss: 0.05634590  Valid_loss:0.00247761 \n",
      "Epoch: 229  Train_loss: 0.05661714  Valid_loss:0.00212758 \n",
      "Epoch: 230  Train_loss: 0.05630741  Valid_loss:0.00235100 \n",
      "Epoch: 231  Train_loss: 0.05632245  Valid_loss:0.00227869 \n",
      "Epoch: 232  Train_loss: 0.05638384  Valid_loss:0.00219160 \n",
      "Epoch: 233  Train_loss: 0.05615373  Valid_loss:0.00240662 \n",
      "Epoch: 234  Train_loss: 0.05641458  Valid_loss:0.00212085 \n",
      "Epoch: 235  Train_loss: 0.05606582  Valid_loss:0.00242094 \n",
      "Epoch: 236  Train_loss: 0.05627131  Valid_loss:0.00215468 \n",
      "Epoch: 237  Train_loss: 0.05602323  Valid_loss:0.00233975 \n",
      "Epoch: 238  Train_loss: 0.05606322  Valid_loss:0.00224698 \n",
      "Epoch: 239  Train_loss: 0.05603309  Valid_loss:0.00223724 \n",
      "Epoch: 240  Train_loss: 0.05590308  Valid_loss:0.00233638 \n",
      "Epoch: 241  Train_loss: 0.05604371  Valid_loss:0.00216761 \n",
      "Epoch: 242  Train_loss: 0.05579582  Valid_loss:0.00238349 \n",
      "Epoch: 243  Train_loss: 0.05599768  Valid_loss:0.00214500 \n",
      "Epoch: 244  Train_loss: 0.05571610  Valid_loss:0.00238317 \n",
      "Epoch: 245  Train_loss: 0.05589473  Valid_loss:0.00215872 \n",
      "Epoch: 246  Train_loss: 0.05565278  Valid_loss:0.00235287 \n",
      "Epoch: 247  Train_loss: 0.05576890  Valid_loss:0.00219015 \n",
      "Epoch: 248  Train_loss: 0.05560034  Valid_loss:0.00231359 \n",
      "Epoch: 249  Train_loss: 0.05564718  Valid_loss:0.00222372 \n",
      "Epoch: 250  Train_loss: 0.05555115  Valid_loss:0.00227859 \n",
      "Epoch: 251  Train_loss: 0.05553854  Valid_loss:0.00225136 \n",
      "Epoch: 252  Train_loss: 0.05550008  Valid_loss:0.00225104 \n",
      "Epoch: 253  Train_loss: 0.05543942  Valid_loss:0.00227374 \n",
      "Epoch: 254  Train_loss: 0.05544867  Valid_loss:0.00222736 \n",
      "Epoch: 255  Train_loss: 0.05534361  Valid_loss:0.00229615 \n",
      "Epoch: 256  Train_loss: 0.05540425  Valid_loss:0.00220058 \n",
      "Epoch: 257  Train_loss: 0.05524549  Valid_loss:0.00232642 \n",
      "Epoch: 258  Train_loss: 0.05538134  Valid_loss:0.00216158 \n",
      "Epoch: 259  Train_loss: 0.05514115  Valid_loss:0.00237885 \n",
      "Epoch: 260  Train_loss: 0.05541574  Valid_loss:0.00209483 \n",
      "Epoch: 261  Train_loss: 0.05503980  Valid_loss:0.00248171 \n",
      "Epoch: 262  Train_loss: 0.05561266  Valid_loss:0.00197262 \n",
      "Epoch: 263  Train_loss: 0.05502079  Valid_loss:0.00270141 \n",
      "Epoch: 264  Train_loss: 0.05633586  Valid_loss:0.00175116 \n",
      "Epoch: 265  Train_loss: 0.05547844  Valid_loss:0.00320420 \n",
      "Epoch: 266  Train_loss: 0.05887582  Valid_loss:0.00140337 \n",
      "Epoch: 267  Train_loss: 0.05765378  Valid_loss:0.00432267 \n",
      "Epoch: 268  Train_loss: 0.06565677  Valid_loss:0.00107640 \n",
      "Epoch: 269  Train_loss: 0.06044240  Valid_loss:0.00543049 \n",
      "Epoch: 270  Train_loss: 0.06532840  Valid_loss:0.00107555 \n",
      "Epoch: 271  Train_loss: 0.05569463  Valid_loss:0.00343453 \n",
      "Epoch: 272  Train_loss: 0.05470117  Valid_loss:0.00256615 \n",
      "Epoch: 273  Train_loss: 0.05950578  Valid_loss:0.00131561 \n",
      "Epoch: 274  Train_loss: 0.05734219  Valid_loss:0.00423932 \n",
      "Epoch: 275  Train_loss: 0.05852185  Valid_loss:0.00138375 \n",
      "Epoch: 276  Train_loss: 0.05461444  Valid_loss:0.00237636 \n",
      "Epoch: 277  Train_loss: 0.05526894  Valid_loss:0.00323701 \n",
      "Epoch: 278  Train_loss: 0.05982037  Valid_loss:0.00126874 \n",
      "Epoch: 279  Train_loss: 0.05528050  Valid_loss:0.00326569 \n",
      "Epoch: 280  Train_loss: 0.05462866  Valid_loss:0.00220113 \n",
      "Epoch: 281  Train_loss: 0.05651817  Valid_loss:0.00158587 \n",
      "Epoch: 282  Train_loss: 0.05539158  Valid_loss:0.00336393 \n",
      "Epoch: 283  Train_loss: 0.05607194  Valid_loss:0.00164998 \n",
      "Epoch: 284  Train_loss: 0.05457405  Valid_loss:0.00215600 \n",
      "Epoch: 285  Train_loss: 0.05471385  Valid_loss:0.00294651 \n",
      "Epoch: 286  Train_loss: 0.05685294  Valid_loss:0.00150834 \n",
      "Epoch: 287  Train_loss: 0.05442100  Valid_loss:0.00267673 \n",
      "Epoch: 288  Train_loss: 0.05432653  Valid_loss:0.00237681 \n",
      "Epoch: 289  Train_loss: 0.05586626  Valid_loss:0.00165081 \n",
      "Epoch: 290  Train_loss: 0.05453474  Valid_loss:0.00288816 \n",
      "Epoch: 291  Train_loss: 0.05477984  Valid_loss:0.00193323 \n",
      "Epoch: 292  Train_loss: 0.05463159  Valid_loss:0.00198776 \n",
      "Epoch: 293  Train_loss: 0.05433512  Valid_loss:0.00275442 \n",
      "Epoch: 294  Train_loss: 0.05535001  Valid_loss:0.00173070 \n",
      "Epoch: 295  Train_loss: 0.05415498  Valid_loss:0.00237361 \n",
      "Epoch: 296  Train_loss: 0.05412485  Valid_loss:0.00240720 \n",
      "Epoch: 297  Train_loss: 0.05511218  Valid_loss:0.00177055 \n",
      "Epoch: 298  Train_loss: 0.05411476  Valid_loss:0.00260677 \n",
      "Epoch: 299  Train_loss: 0.05432841  Valid_loss:0.00205598 \n",
      "Epoch: 300  Train_loss: 0.05439864  Valid_loss:0.00200205 \n",
      "Epoch: 301  Train_loss: 0.05402363  Valid_loss:0.00256923 \n",
      "Epoch: 302  Train_loss: 0.05466433  Valid_loss:0.00186854 \n",
      "Epoch: 303  Train_loss: 0.05398126  Valid_loss:0.00230195 \n",
      "Epoch: 304  Train_loss: 0.05394869  Valid_loss:0.00231961 \n",
      "Epoch: 305  Train_loss: 0.05450686  Valid_loss:0.00189901 \n",
      "Epoch: 306  Train_loss: 0.05387662  Valid_loss:0.00247891 \n",
      "Epoch: 307  Train_loss: 0.05413754  Valid_loss:0.00205224 \n",
      "Epoch: 308  Train_loss: 0.05403535  Valid_loss:0.00210476 \n",
      "Epoch: 309  Train_loss: 0.05380233  Valid_loss:0.00241207 \n",
      "Epoch: 310  Train_loss: 0.05428226  Valid_loss:0.00194113 \n",
      "Epoch: 311  Train_loss: 0.05377131  Valid_loss:0.00233613 \n",
      "Epoch: 312  Train_loss: 0.05384491  Valid_loss:0.00218679 \n",
      "Epoch: 313  Train_loss: 0.05402201  Valid_loss:0.00203535 \n",
      "Epoch: 314  Train_loss: 0.05368324  Valid_loss:0.00239533 \n",
      "Epoch: 315  Train_loss: 0.05400954  Valid_loss:0.00201575 \n",
      "Epoch: 316  Train_loss: 0.05370378  Valid_loss:0.00224135 \n",
      "Epoch: 317  Train_loss: 0.05367801  Valid_loss:0.00224441 \n",
      "Epoch: 318  Train_loss: 0.05390530  Valid_loss:0.00203489 \n",
      "Epoch: 319  Train_loss: 0.05357563  Valid_loss:0.00235095 \n",
      "Epoch: 320  Train_loss: 0.05380338  Valid_loss:0.00206895 \n",
      "Epoch: 321  Train_loss: 0.05361889  Valid_loss:0.00220259 \n",
      "Epoch: 322  Train_loss: 0.05355735  Valid_loss:0.00225063 \n",
      "Epoch: 323  Train_loss: 0.05375230  Valid_loss:0.00205751 \n",
      "Epoch: 324  Train_loss: 0.05347428  Valid_loss:0.00231461 \n",
      "Epoch: 325  Train_loss: 0.05365300  Valid_loss:0.00209329 \n",
      "Epoch: 326  Train_loss: 0.05350694  Valid_loss:0.00220020 \n",
      "Epoch: 327  Train_loss: 0.05345885  Valid_loss:0.00223024 \n",
      "Epoch: 328  Train_loss: 0.05359494  Valid_loss:0.00208651 \n",
      "Epoch: 329  Train_loss: 0.05337450  Valid_loss:0.00228905 \n",
      "Epoch: 330  Train_loss: 0.05353412  Valid_loss:0.00209791 \n",
      "Epoch: 331  Train_loss: 0.05337996  Valid_loss:0.00221767 \n",
      "Epoch: 332  Train_loss: 0.05337805  Valid_loss:0.00219496 \n",
      "Epoch: 333  Train_loss: 0.05343617  Valid_loss:0.00212182 \n",
      "Epoch: 334  Train_loss: 0.05328087  Valid_loss:0.00226217 \n",
      "Epoch: 335  Train_loss: 0.05342169  Valid_loss:0.00209944 \n",
      "Epoch: 336  Train_loss: 0.05325362  Valid_loss:0.00223932 \n",
      "Epoch: 337  Train_loss: 0.05331253  Valid_loss:0.00215257 \n",
      "Epoch: 338  Train_loss: 0.05327473  Valid_loss:0.00216769 \n",
      "Epoch: 339  Train_loss: 0.05320503  Valid_loss:0.00221942 \n",
      "Epoch: 340  Train_loss: 0.05328919  Valid_loss:0.00211811 \n",
      "Epoch: 341  Train_loss: 0.05314467  Valid_loss:0.00224263 \n",
      "Epoch: 342  Train_loss: 0.05324287  Valid_loss:0.00212114 \n",
      "Epoch: 343  Train_loss: 0.05312488  Valid_loss:0.00221444 \n",
      "Epoch: 344  Train_loss: 0.05315467  Valid_loss:0.00216111 \n",
      "Epoch: 345  Train_loss: 0.05312814  Valid_loss:0.00216660 \n",
      "Epoch: 346  Train_loss: 0.05307213  Valid_loss:0.00220344 \n",
      "Epoch: 347  Train_loss: 0.05312459  Valid_loss:0.00213247 \n",
      "Epoch: 348  Train_loss: 0.05301493  Valid_loss:0.00222285 \n",
      "Epoch: 349  Train_loss: 0.05309192  Valid_loss:0.00212537 \n",
      "Epoch: 350  Train_loss: 0.05298035  Valid_loss:0.00221549 \n",
      "Epoch: 351  Train_loss: 0.05303462  Valid_loss:0.00213943 \n",
      "Epoch: 352  Train_loss: 0.05296044  Valid_loss:0.00219209 \n",
      "Epoch: 353  Train_loss: 0.05296884  Valid_loss:0.00216286 \n",
      "Epoch: 354  Train_loss: 0.05294593  Valid_loss:0.00216580 \n",
      "Epoch: 355  Train_loss: 0.05290786  Valid_loss:0.00218444 \n",
      "Epoch: 356  Train_loss: 0.05292816  Valid_loss:0.00214515 \n",
      "Epoch: 357  Train_loss: 0.05285576  Valid_loss:0.00219866 \n",
      "Epoch: 358  Train_loss: 0.05290325  Valid_loss:0.00213235 \n",
      "Epoch: 359  Train_loss: 0.05281081  Valid_loss:0.00220584 \n",
      "Epoch: 360  Train_loss: 0.05287305  Valid_loss:0.00212476 \n",
      "Epoch: 361  Train_loss: 0.05276969  Valid_loss:0.00220922 \n",
      "Epoch: 362  Train_loss: 0.05284112  Valid_loss:0.00211908 \n",
      "Epoch: 363  Train_loss: 0.05272918  Valid_loss:0.00221244 \n",
      "Epoch: 364  Train_loss: 0.05281170  Valid_loss:0.00211168 \n",
      "Epoch: 365  Train_loss: 0.05268633  Valid_loss:0.00221925 \n",
      "Epoch: 366  Train_loss: 0.05278987  Valid_loss:0.00209872 \n",
      "Epoch: 367  Train_loss: 0.05263824  Valid_loss:0.00223431 \n",
      "Epoch: 368  Train_loss: 0.05278325  Valid_loss:0.00207521 \n",
      "Epoch: 369  Train_loss: 0.05258215  Valid_loss:0.00226488 \n",
      "Epoch: 370  Train_loss: 0.05280827  Valid_loss:0.00203280 \n",
      "Epoch: 371  Train_loss: 0.05251774  Valid_loss:0.00232514 \n",
      "Epoch: 372  Train_loss: 0.05290703  Valid_loss:0.00195592 \n",
      "Epoch: 373  Train_loss: 0.05246172  Valid_loss:0.00244627 \n",
      "Epoch: 374  Train_loss: 0.05320681  Valid_loss:0.00181544 \n",
      "Epoch: 375  Train_loss: 0.05251604  Valid_loss:0.00270460 \n",
      "Epoch: 376  Train_loss: 0.05413521  Valid_loss:0.00156696 \n",
      "Epoch: 377  Train_loss: 0.05314383  Valid_loss:0.00328841 \n",
      "Epoch: 378  Train_loss: 0.05720743  Valid_loss:0.00118177 \n",
      "Epoch: 379  Train_loss: 0.05584578  Valid_loss:0.00463296 \n",
      "Epoch: 380  Train_loss: 0.06627752  Valid_loss:0.00078436 \n",
      "Epoch: 381  Train_loss: 0.06062343  Valid_loss:0.00650612 \n",
      "Epoch: 382  Train_loss: 0.07179309  Valid_loss:0.00068688 \n",
      "Epoch: 383  Train_loss: 0.05549552  Valid_loss:0.00446151 \n",
      "Epoch: 384  Train_loss: 0.05252606  Valid_loss:0.00206489 \n",
      "Epoch: 385  Train_loss: 0.05690258  Valid_loss:0.00117752 \n",
      "Epoch: 386  Train_loss: 0.05632009  Valid_loss:0.00477305 \n",
      "Epoch: 387  Train_loss: 0.05996098  Valid_loss:0.00097123 \n",
      "Epoch: 388  Train_loss: 0.05241335  Valid_loss:0.00265015 \n",
      "Epoch: 389  Train_loss: 0.05310610  Valid_loss:0.00323092 \n",
      "Epoch: 390  Train_loss: 0.05996301  Valid_loss:0.00095986 \n",
      "Epoch: 391  Train_loss: 0.05369687  Valid_loss:0.00355509 \n",
      "Epoch: 392  Train_loss: 0.05246322  Valid_loss:0.00204292 \n",
      "Epoch: 393  Train_loss: 0.05506179  Valid_loss:0.00133411 \n",
      "Epoch: 394  Train_loss: 0.05370269  Valid_loss:0.00354509 \n",
      "Epoch: 395  Train_loss: 0.05418056  Valid_loss:0.00145886 \n",
      "Epoch: 396  Train_loss: 0.05259629  Valid_loss:0.00191675 \n",
      "Epoch: 397  Train_loss: 0.05296026  Valid_loss:0.00311684 \n",
      "Epoch: 398  Train_loss: 0.05543099  Valid_loss:0.00127119 \n",
      "Epoch: 399  Train_loss: 0.05227400  Valid_loss:0.00245453 \n",
      "Epoch: 400  Train_loss: 0.05232316  Valid_loss:0.00256657 \n",
      "Epoch: 401  Train_loss: 0.05491295  Valid_loss:0.00132674 \n",
      "Epoch: 402  Train_loss: 0.05247026  Valid_loss:0.00275865 \n",
      "Epoch: 403  Train_loss: 0.05231085  Valid_loss:0.00207732 \n",
      "Epoch: 404  Train_loss: 0.05357049  Valid_loss:0.00154659 \n",
      "Epoch: 405  Train_loss: 0.05249235  Valid_loss:0.00280348 \n",
      "Epoch: 406  Train_loss: 0.05284322  Valid_loss:0.00174472 \n",
      "Epoch: 407  Train_loss: 0.05255834  Valid_loss:0.00186273 \n",
      "Epoch: 408  Train_loss: 0.05230666  Valid_loss:0.00264582 \n",
      "Epoch: 409  Train_loss: 0.05332261  Valid_loss:0.00158925 \n",
      "Epoch: 410  Train_loss: 0.05216367  Valid_loss:0.00218303 \n",
      "Epoch: 411  Train_loss: 0.05212850  Valid_loss:0.00236631 \n",
      "Epoch: 412  Train_loss: 0.05325188  Valid_loss:0.00159808 \n",
      "Epoch: 413  Train_loss: 0.05211269  Valid_loss:0.00240680 \n",
      "Epoch: 414  Train_loss: 0.05219248  Valid_loss:0.00206764 \n",
      "Epoch: 415  Train_loss: 0.05274504  Valid_loss:0.00174179 \n",
      "Epoch: 416  Train_loss: 0.05209578  Valid_loss:0.00246802 \n",
      "Epoch: 417  Train_loss: 0.05247824  Valid_loss:0.00184477 \n",
      "Epoch: 418  Train_loss: 0.05225809  Valid_loss:0.00196802 \n",
      "Epoch: 419  Train_loss: 0.05202863  Valid_loss:0.00236405 \n",
      "Epoch: 420  Train_loss: 0.05266142  Valid_loss:0.00175249 \n",
      "Epoch: 421  Train_loss: 0.05202821  Valid_loss:0.00219051 \n",
      "Epoch: 422  Train_loss: 0.05203115  Valid_loss:0.00215992 \n",
      "Epoch: 423  Train_loss: 0.05250897  Valid_loss:0.00180065 \n",
      "Epoch: 424  Train_loss: 0.05196336  Valid_loss:0.00231161 \n",
      "Epoch: 425  Train_loss: 0.05218839  Valid_loss:0.00196104 \n",
      "Epoch: 426  Train_loss: 0.05218520  Valid_loss:0.00195549 \n",
      "Epoch: 427  Train_loss: 0.05192945  Valid_loss:0.00228012 \n",
      "Epoch: 428  Train_loss: 0.05233207  Valid_loss:0.00185741 \n",
      "Epoch: 429  Train_loss: 0.05196329  Valid_loss:0.00213569 \n",
      "Epoch: 430  Train_loss: 0.05195303  Valid_loss:0.00213379 \n",
      "Epoch: 431  Train_loss: 0.05224692  Valid_loss:0.00188484 \n",
      "Epoch: 432  Train_loss: 0.05188023  Valid_loss:0.00223527 \n",
      "Epoch: 433  Train_loss: 0.05207550  Valid_loss:0.00197844 \n",
      "Epoch: 434  Train_loss: 0.05202024  Valid_loss:0.00201309 \n",
      "Epoch: 435  Train_loss: 0.05186041  Valid_loss:0.00219669 \n",
      "Epoch: 436  Train_loss: 0.05214299  Valid_loss:0.00191299 \n",
      "Epoch: 437  Train_loss: 0.05186374  Valid_loss:0.00214918 \n",
      "Epoch: 438  Train_loss: 0.05191677  Valid_loss:0.00206836 \n",
      "Epoch: 439  Train_loss: 0.05202485  Valid_loss:0.00196809 \n",
      "Epoch: 440  Train_loss: 0.05180893  Valid_loss:0.00218775 \n",
      "Epoch: 441  Train_loss: 0.05200773  Valid_loss:0.00196508 \n",
      "Epoch: 442  Train_loss: 0.05185609  Valid_loss:0.00208730 \n",
      "Epoch: 443  Train_loss: 0.05182752  Valid_loss:0.00210857 \n",
      "Epoch: 444  Train_loss: 0.05197252  Valid_loss:0.00196741 \n",
      "Epoch: 445  Train_loss: 0.05177128  Valid_loss:0.00215855 \n",
      "Epoch: 446  Train_loss: 0.05190318  Valid_loss:0.00200343 \n",
      "Epoch: 447  Train_loss: 0.05183036  Valid_loss:0.00205872 \n",
      "Epoch: 448  Train_loss: 0.05176999  Valid_loss:0.00211497 \n",
      "Epoch: 449  Train_loss: 0.05190110  Valid_loss:0.00198110 \n",
      "Epoch: 450  Train_loss: 0.05173583  Valid_loss:0.00213344 \n",
      "Epoch: 451  Train_loss: 0.05182897  Valid_loss:0.00202194 \n",
      "Epoch: 452  Train_loss: 0.05178542  Valid_loss:0.00205229 \n",
      "Epoch: 453  Train_loss: 0.05172692  Valid_loss:0.00210497 \n",
      "Epoch: 454  Train_loss: 0.05183084  Valid_loss:0.00199547 \n",
      "Epoch: 455  Train_loss: 0.05169732  Valid_loss:0.00211734 \n",
      "Epoch: 456  Train_loss: 0.05177517  Valid_loss:0.00202466 \n",
      "Epoch: 457  Train_loss: 0.05173026  Valid_loss:0.00205726 \n",
      "Epoch: 458  Train_loss: 0.05169199  Valid_loss:0.00208766 \n",
      "Epoch: 459  Train_loss: 0.05176406  Valid_loss:0.00200878 \n",
      "Epoch: 460  Train_loss: 0.05165816  Valid_loss:0.00210503 \n",
      "Epoch: 461  Train_loss: 0.05172992  Valid_loss:0.00202103 \n",
      "Epoch: 462  Train_loss: 0.05167329  Valid_loss:0.00206572 \n",
      "Epoch: 463  Train_loss: 0.05166259  Valid_loss:0.00206693 \n",
      "Epoch: 464  Train_loss: 0.05169955  Valid_loss:0.00202212 \n",
      "Epoch: 465  Train_loss: 0.05162169  Valid_loss:0.00209164 \n",
      "Epoch: 466  Train_loss: 0.05168702  Valid_loss:0.00201635 \n",
      "Epoch: 467  Train_loss: 0.05161836  Valid_loss:0.00207406 \n",
      "Epoch: 468  Train_loss: 0.05163813  Valid_loss:0.00204385 \n",
      "Epoch: 469  Train_loss: 0.05163446  Valid_loss:0.00203844 \n",
      "Epoch: 470  Train_loss: 0.05159283  Valid_loss:0.00207170 \n",
      "Epoch: 471  Train_loss: 0.05163790  Valid_loss:0.00201815 \n",
      "Epoch: 472  Train_loss: 0.05157183  Valid_loss:0.00207491 \n",
      "Epoch: 473  Train_loss: 0.05161322  Valid_loss:0.00202376 \n",
      "Epoch: 474  Train_loss: 0.05157117  Valid_loss:0.00205606 \n",
      "Epoch: 475  Train_loss: 0.05157478  Valid_loss:0.00204317 \n",
      "Epoch: 476  Train_loss: 0.05157630  Valid_loss:0.00203293 \n",
      "Epoch: 477  Train_loss: 0.05154210  Valid_loss:0.00205871 \n",
      "Epoch: 478  Train_loss: 0.05157277  Valid_loss:0.00201951 \n",
      "Epoch: 479  Train_loss: 0.05152249  Valid_loss:0.00206103 \n",
      "Epoch: 480  Train_loss: 0.05155470  Valid_loss:0.00201983 \n",
      "Epoch: 481  Train_loss: 0.05151458  Valid_loss:0.00205097 \n",
      "Epoch: 482  Train_loss: 0.05152756  Valid_loss:0.00202905 \n",
      "Epoch: 483  Train_loss: 0.05151244  Valid_loss:0.00203551 \n",
      "Epoch: 484  Train_loss: 0.05149961  Valid_loss:0.00203985 \n",
      "Epoch: 485  Train_loss: 0.05150887  Valid_loss:0.00202232 \n",
      "Epoch: 486  Train_loss: 0.05147719  Valid_loss:0.00204574 \n",
      "Epoch: 487  Train_loss: 0.05149911  Valid_loss:0.00201551 \n",
      "Epoch: 488  Train_loss: 0.05146109  Valid_loss:0.00204519 \n",
      "Epoch: 489  Train_loss: 0.05148394  Valid_loss:0.00201406 \n",
      "Epoch: 490  Train_loss: 0.05144949  Valid_loss:0.00204013 \n",
      "Epoch: 491  Train_loss: 0.05146552  Valid_loss:0.00201585 \n",
      "Epoch: 492  Train_loss: 0.05144015  Valid_loss:0.00203300 \n",
      "Epoch: 493  Train_loss: 0.05144649  Valid_loss:0.00201843 \n",
      "Epoch: 494  Train_loss: 0.05143096  Valid_loss:0.00202592 \n",
      "Epoch: 495  Train_loss: 0.05142864  Valid_loss:0.00202020 \n",
      "Epoch: 496  Train_loss: 0.05142130  Valid_loss:0.00201964 \n",
      "Epoch: 497  Train_loss: 0.05141170  Valid_loss:0.00202135 \n",
      "Epoch: 498  Train_loss: 0.05141116  Valid_loss:0.00201410 \n",
      "Epoch: 499  Train_loss: 0.05139530  Valid_loss:0.00202220 \n",
      "Epoch: 500  Train_loss: 0.05140148  Valid_loss:0.00200832 \n",
      "Epoch: 501  Train_loss: 0.05137884  Valid_loss:0.00202335 \n",
      "Epoch: 502  Train_loss: 0.05139258  Valid_loss:0.00200200 \n",
      "Epoch: 503  Train_loss: 0.05136185  Valid_loss:0.00202522 \n",
      "Epoch: 504  Train_loss: 0.05138525  Valid_loss:0.00199454 \n",
      "Epoch: 505  Train_loss: 0.05134370  Valid_loss:0.00202880 \n",
      "Epoch: 506  Train_loss: 0.05138069  Valid_loss:0.00198472 \n",
      "Epoch: 507  Train_loss: 0.05132299  Valid_loss:0.00203561 \n",
      "Epoch: 508  Train_loss: 0.05138166  Valid_loss:0.00197050 \n",
      "Epoch: 509  Train_loss: 0.05129773  Valid_loss:0.00204861 \n",
      "Epoch: 510  Train_loss: 0.05139329  Valid_loss:0.00194834 \n",
      "Epoch: 511  Train_loss: 0.05126523  Valid_loss:0.00207334 \n",
      "Epoch: 512  Train_loss: 0.05142736  Valid_loss:0.00191129 \n",
      "Epoch: 513  Train_loss: 0.05122311  Valid_loss:0.00212101 \n",
      "Epoch: 514  Train_loss: 0.05151419  Valid_loss:0.00184640 \n",
      "Epoch: 515  Train_loss: 0.05117862  Valid_loss:0.00221602 \n",
      "Epoch: 516  Train_loss: 0.05174134  Valid_loss:0.00172942 \n",
      "Epoch: 517  Train_loss: 0.05119283  Valid_loss:0.00241529 \n",
      "Epoch: 518  Train_loss: 0.05240204  Valid_loss:0.00151910 \n",
      "Epoch: 519  Train_loss: 0.05157758  Valid_loss:0.00286580 \n",
      "Epoch: 520  Train_loss: 0.05460334  Valid_loss:0.00116686 \n",
      "Epoch: 521  Train_loss: 0.05364460  Valid_loss:0.00398991 \n",
      "Epoch: 522  Train_loss: 0.06264958  Valid_loss:0.00070111 \n",
      "Epoch: 523  Train_loss: 0.06065026  Valid_loss:0.00672527 \n",
      "Epoch: 524  Train_loss: 0.08403420  Valid_loss:0.00041058 \n",
      "Epoch: 525  Train_loss: 0.06203786  Valid_loss:0.00719278 \n",
      "Epoch: 526  Train_loss: 0.06078233  Valid_loss:0.00075385 \n",
      "Epoch: 527  Train_loss: 0.05119520  Valid_loss:0.00208627 \n",
      "Epoch: 528  Train_loss: 0.05478315  Valid_loss:0.00435870 \n",
      "Epoch: 529  Train_loss: 0.06911172  Valid_loss:0.00053222 \n",
      "Epoch: 530  Train_loss: 0.05436783  Valid_loss:0.00414278 \n",
      "Epoch: 531  Train_loss: 0.05121748  Valid_loss:0.00208613 \n",
      "Epoch: 532  Train_loss: 0.05761197  Valid_loss:0.00087984 \n",
      "Epoch: 533  Train_loss: 0.05460522  Valid_loss:0.00417859 \n",
      "Epoch: 534  Train_loss: 0.05382264  Valid_loss:0.00119881 \n",
      "Epoch: 535  Train_loss: 0.05201713  Valid_loss:0.00154910 \n",
      "Epoch: 536  Train_loss: 0.05331960  Valid_loss:0.00358896 \n",
      "Epoch: 537  Train_loss: 0.05659716  Valid_loss:0.00092778 \n",
      "Epoch: 538  Train_loss: 0.05125863  Valid_loss:0.00219285 \n",
      "Epoch: 539  Train_loss: 0.05211770  Valid_loss:0.00296112 \n",
      "Epoch: 540  Train_loss: 0.05678489  Valid_loss:0.00090807 \n",
      "Epoch: 541  Train_loss: 0.05155060  Valid_loss:0.00256170 \n",
      "Epoch: 542  Train_loss: 0.05142814  Valid_loss:0.00243972 \n",
      "Epoch: 543  Train_loss: 0.05534143  Valid_loss:0.00101229 \n",
      "Epoch: 544  Train_loss: 0.05172208  Valid_loss:0.00268283 \n",
      "Epoch: 545  Train_loss: 0.05126020  Valid_loss:0.00204755 \n",
      "Epoch: 546  Train_loss: 0.05370378  Valid_loss:0.00118492 \n",
      "Epoch: 547  Train_loss: 0.05170636  Valid_loss:0.00266786 \n",
      "Epoch: 548  Train_loss: 0.05145605  Valid_loss:0.00176849 \n",
      "Epoch: 549  Train_loss: 0.05248275  Valid_loss:0.00139197 \n",
      "Epoch: 550  Train_loss: 0.05159116  Valid_loss:0.00258519 \n",
      "Epoch: 551  Train_loss: 0.05180835  Valid_loss:0.00158429 \n",
      "Epoch: 552  Train_loss: 0.05174657  Valid_loss:0.00160719 \n",
      "Epoch: 553  Train_loss: 0.05143759  Valid_loss:0.00246250 \n",
      "Epoch: 554  Train_loss: 0.05215001  Valid_loss:0.00146988 \n",
      "Epoch: 555  Train_loss: 0.05134031  Valid_loss:0.00184044 \n",
      "Epoch: 556  Train_loss: 0.05126447  Valid_loss:0.00226580 \n",
      "Epoch: 557  Train_loss: 0.05219019  Valid_loss:0.00145745 \n",
      "Epoch: 558  Train_loss: 0.05122083  Valid_loss:0.00199339 \n",
      "Epoch: 559  Train_loss: 0.05119726  Valid_loss:0.00210584 \n",
      "Epoch: 560  Train_loss: 0.05206844  Valid_loss:0.00148954 \n",
      "Epoch: 561  Train_loss: 0.05118417  Valid_loss:0.00209982 \n",
      "Epoch: 562  Train_loss: 0.05121810  Valid_loss:0.00195081 \n",
      "Epoch: 563  Train_loss: 0.05182014  Valid_loss:0.00156657 \n",
      "Epoch: 564  Train_loss: 0.05116808  Valid_loss:0.00215220 \n",
      "Epoch: 565  Train_loss: 0.05131865  Valid_loss:0.00181877 \n",
      "Epoch: 566  Train_loss: 0.05154598  Valid_loss:0.00167585 \n",
      "Epoch: 567  Train_loss: 0.05114650  Valid_loss:0.00214849 \n",
      "Epoch: 568  Train_loss: 0.05144434  Valid_loss:0.00172547 \n",
      "Epoch: 569  Train_loss: 0.05132532  Valid_loss:0.00179975 \n",
      "Epoch: 570  Train_loss: 0.05112473  Valid_loss:0.00209449 \n",
      "Epoch: 571  Train_loss: 0.05151893  Valid_loss:0.00168115 \n",
      "Epoch: 572  Train_loss: 0.05118799  Valid_loss:0.00191590 \n",
      "Epoch: 573  Train_loss: 0.05112823  Valid_loss:0.00200572 \n",
      "Epoch: 574  Train_loss: 0.05149400  Valid_loss:0.00168853 \n",
      "Epoch: 575  Train_loss: 0.05111922  Valid_loss:0.00200077 \n",
      "Epoch: 576  Train_loss: 0.05117621  Valid_loss:0.00190622 \n",
      "Epoch: 577  Train_loss: 0.05138337  Valid_loss:0.00174148 \n",
      "Epoch: 578  Train_loss: 0.05108855  Valid_loss:0.00203644 \n",
      "Epoch: 579  Train_loss: 0.05125243  Valid_loss:0.00182288 \n",
      "Epoch: 580  Train_loss: 0.05124733  Valid_loss:0.00182359 \n",
      "Epoch: 581  Train_loss: 0.05107928  Valid_loss:0.00201859 \n",
      "Epoch: 582  Train_loss: 0.05130558  Valid_loss:0.00177719 \n",
      "Epoch: 583  Train_loss: 0.05114087  Valid_loss:0.00190915 \n",
      "Epoch: 584  Train_loss: 0.05109628  Valid_loss:0.00196033 \n",
      "Epoch: 585  Train_loss: 0.05129152  Valid_loss:0.00177868 \n",
      "Epoch: 586  Train_loss: 0.05108091  Valid_loss:0.00196953 \n",
      "Epoch: 587  Train_loss: 0.05114246  Valid_loss:0.00188892 \n",
      "Epoch: 588  Train_loss: 0.05121702  Valid_loss:0.00182165 \n",
      "Epoch: 589  Train_loss: 0.05105790  Valid_loss:0.00198482 \n",
      "Epoch: 590  Train_loss: 0.05119162  Valid_loss:0.00183483 \n",
      "Epoch: 591  Train_loss: 0.05112958  Valid_loss:0.00188498 \n",
      "Epoch: 592  Train_loss: 0.05106421  Valid_loss:0.00195499 \n",
      "Epoch: 593  Train_loss: 0.05120083  Valid_loss:0.00181879 \n",
      "Epoch: 594  Train_loss: 0.05106840  Valid_loss:0.00193834 \n",
      "Epoch: 595  Train_loss: 0.05109647  Valid_loss:0.00190168 \n",
      "Epoch: 596  Train_loss: 0.05115708  Valid_loss:0.00184302 \n",
      "Epoch: 597  Train_loss: 0.05104256  Valid_loss:0.00195630 \n",
      "Epoch: 598  Train_loss: 0.05113285  Valid_loss:0.00185653 \n",
      "Epoch: 599  Train_loss: 0.05109259  Valid_loss:0.00188950 \n",
      "Epoch: 600  Train_loss: 0.05104771  Valid_loss:0.00193414 \n",
      "Epoch: 601  Train_loss: 0.05113710  Valid_loss:0.00184324 \n",
      "Epoch: 602  Train_loss: 0.05104497  Valid_loss:0.00192813 \n",
      "Epoch: 603  Train_loss: 0.05107452  Valid_loss:0.00189195 \n",
      "Epoch: 604  Train_loss: 0.05110007  Valid_loss:0.00186453 \n",
      "Epoch: 605  Train_loss: 0.05102804  Valid_loss:0.00193486 \n",
      "Epoch: 606  Train_loss: 0.05109716  Valid_loss:0.00186043 \n",
      "Epoch: 607  Train_loss: 0.05105116  Valid_loss:0.00190034 \n",
      "Epoch: 608  Train_loss: 0.05103869  Valid_loss:0.00190967 \n",
      "Epoch: 609  Train_loss: 0.05108735  Valid_loss:0.00185908 \n",
      "Epoch: 610  Train_loss: 0.05102098  Valid_loss:0.00192145 \n",
      "Epoch: 611  Train_loss: 0.05106078  Valid_loss:0.00187632 \n",
      "Epoch: 612  Train_loss: 0.05105028  Valid_loss:0.00188283 \n",
      "Epoch: 613  Train_loss: 0.05101834  Valid_loss:0.00191227 \n",
      "Epoch: 614  Train_loss: 0.05106545  Valid_loss:0.00186202 \n",
      "Epoch: 615  Train_loss: 0.05101663  Valid_loss:0.00190642 \n",
      "Epoch: 616  Train_loss: 0.05103399  Valid_loss:0.00188476 \n",
      "Epoch: 617  Train_loss: 0.05104160  Valid_loss:0.00187400 \n",
      "Epoch: 618  Train_loss: 0.05100572  Valid_loss:0.00190706 \n",
      "Epoch: 619  Train_loss: 0.05104350  Valid_loss:0.00186567 \n",
      "Epoch: 620  Train_loss: 0.05101046  Valid_loss:0.00189458 \n",
      "Epoch: 621  Train_loss: 0.05101528  Valid_loss:0.00188622 \n",
      "Epoch: 622  Train_loss: 0.05102856  Valid_loss:0.00186988 \n",
      "Epoch: 623  Train_loss: 0.05099614  Valid_loss:0.00189923 \n",
      "Epoch: 624  Train_loss: 0.05102473  Valid_loss:0.00186705 \n",
      "Epoch: 625  Train_loss: 0.05100186  Valid_loss:0.00188621 \n",
      "Epoch: 626  Train_loss: 0.05100152  Valid_loss:0.00188320 \n",
      "Epoch: 627  Train_loss: 0.05101425  Valid_loss:0.00186745 \n",
      "Epoch: 628  Train_loss: 0.05098739  Valid_loss:0.00189123 \n",
      "Epoch: 629  Train_loss: 0.05100928  Valid_loss:0.00186589 \n",
      "Epoch: 630  Train_loss: 0.05099160  Valid_loss:0.00188015 \n",
      "Epoch: 631  Train_loss: 0.05099087  Valid_loss:0.00187768 \n",
      "Epoch: 632  Train_loss: 0.05100013  Valid_loss:0.00186533 \n",
      "Epoch: 633  Train_loss: 0.05097900  Valid_loss:0.00188345 \n",
      "Epoch: 634  Train_loss: 0.05099628  Valid_loss:0.00186297 \n",
      "Epoch: 635  Train_loss: 0.05098074  Valid_loss:0.00187526 \n",
      "Epoch: 636  Train_loss: 0.05098188  Valid_loss:0.00187094 \n",
      "Epoch: 637  Train_loss: 0.05098667  Valid_loss:0.00186316 \n",
      "Epoch: 638  Train_loss: 0.05097096  Valid_loss:0.00187587 \n",
      "Epoch: 639  Train_loss: 0.05098464  Valid_loss:0.00185917 \n",
      "Epoch: 640  Train_loss: 0.05096999  Valid_loss:0.00187077 \n",
      "Epoch: 641  Train_loss: 0.05097401  Valid_loss:0.00186367 \n",
      "Epoch: 642  Train_loss: 0.05097380  Valid_loss:0.00186092 \n",
      "Epoch: 643  Train_loss: 0.05096377  Valid_loss:0.00186808 \n",
      "Epoch: 644  Train_loss: 0.05097360  Valid_loss:0.00185534 \n",
      "Epoch: 645  Train_loss: 0.05096014  Valid_loss:0.00186585 \n",
      "Epoch: 646  Train_loss: 0.05096659  Valid_loss:0.00185650 \n",
      "Epoch: 647  Train_loss: 0.05096165  Valid_loss:0.00185852 \n",
      "Epoch: 648  Train_loss: 0.05095747  Valid_loss:0.00185984 \n",
      "Epoch: 649  Train_loss: 0.05096248  Valid_loss:0.00185206 \n",
      "Epoch: 650  Train_loss: 0.05095181  Valid_loss:0.00185996 \n",
      "Epoch: 651  Train_loss: 0.05095889  Valid_loss:0.00185011 \n",
      "Epoch: 652  Train_loss: 0.05095062  Valid_loss:0.00185552 \n",
      "Epoch: 653  Train_loss: 0.05095186  Valid_loss:0.00185152 \n",
      "Epoch: 654  Train_loss: 0.05095119  Valid_loss:0.00184942 \n",
      "Epoch: 655  Train_loss: 0.05094525  Valid_loss:0.00185268 \n",
      "Epoch: 656  Train_loss: 0.05095000  Valid_loss:0.00184522 \n",
      "Epoch: 657  Train_loss: 0.05094157  Valid_loss:0.00185103 \n",
      "Epoch: 658  Train_loss: 0.05094584  Valid_loss:0.00184401 \n",
      "Epoch: 659  Train_loss: 0.05094047  Valid_loss:0.00184679 \n",
      "Epoch: 660  Train_loss: 0.05094016  Valid_loss:0.00184448 \n",
      "Epoch: 661  Train_loss: 0.05093998  Valid_loss:0.00184201 \n",
      "Epoch: 662  Train_loss: 0.05093506  Valid_loss:0.00184441 \n",
      "Epoch: 663  Train_loss: 0.05093833  Valid_loss:0.00183855 \n",
      "Epoch: 664  Train_loss: 0.05093176  Valid_loss:0.00184259 \n",
      "Epoch: 665  Train_loss: 0.05093488  Valid_loss:0.00183692 \n",
      "Epoch: 666  Train_loss: 0.05093013  Valid_loss:0.00183919 \n",
      "Epoch: 667  Train_loss: 0.05093044  Valid_loss:0.00183634 \n",
      "Epoch: 668  Train_loss: 0.05092900  Valid_loss:0.00183529 \n",
      "Epoch: 669  Train_loss: 0.05092612  Valid_loss:0.00183571 \n",
      "Epoch: 670  Train_loss: 0.05092742  Valid_loss:0.00183196 \n",
      "Epoch: 671  Train_loss: 0.05092270  Valid_loss:0.00183425 \n",
      "Epoch: 672  Train_loss: 0.05092495  Valid_loss:0.00182963 \n",
      "Epoch: 673  Train_loss: 0.05092034  Valid_loss:0.00183180 \n",
      "Epoch: 674  Train_loss: 0.05092169  Valid_loss:0.00182808 \n",
      "Epoch: 675  Train_loss: 0.05091868  Valid_loss:0.00182875 \n",
      "Epoch: 676  Train_loss: 0.05091812  Valid_loss:0.00182692 \n",
      "Epoch: 677  Train_loss: 0.05091713  Valid_loss:0.00182564 \n",
      "Epoch: 678  Train_loss: 0.05091486  Valid_loss:0.00182561 \n",
      "Epoch: 679  Train_loss: 0.05091536  Valid_loss:0.00182280 \n",
      "Epoch: 680  Train_loss: 0.05091194  Valid_loss:0.00182394 \n",
      "Epoch: 681  Train_loss: 0.05091322  Valid_loss:0.00182040 \n",
      "Epoch: 682  Train_loss: 0.05090955  Valid_loss:0.00182186 \n",
      "Epoch: 683  Train_loss: 0.05091086  Valid_loss:0.00181837 \n",
      "Epoch: 684  Train_loss: 0.05090747  Valid_loss:0.00181949 \n",
      "Epoch: 685  Train_loss: 0.05090821  Valid_loss:0.00181661 \n",
      "Epoch: 686  Train_loss: 0.05090569  Valid_loss:0.00181693 \n",
      "Epoch: 687  Train_loss: 0.05090556  Valid_loss:0.00181488 \n",
      "Epoch: 688  Train_loss: 0.05090389  Valid_loss:0.00181436 \n",
      "Epoch: 689  Train_loss: 0.05090301  Valid_loss:0.00181313 \n",
      "Epoch: 690  Train_loss: 0.05090218  Valid_loss:0.00181194 \n",
      "Epoch: 691  Train_loss: 0.05090065  Valid_loss:0.00181131 \n",
      "Epoch: 692  Train_loss: 0.05090028  Valid_loss:0.00180958 \n",
      "Epoch: 693  Train_loss: 0.05089839  Valid_loss:0.00180939 \n",
      "Epoch: 694  Train_loss: 0.05089843  Valid_loss:0.00180729 \n",
      "Epoch: 695  Train_loss: 0.05089633  Valid_loss:0.00180743 \n",
      "Epoch: 696  Train_loss: 0.05089662  Valid_loss:0.00180509 \n",
      "Epoch: 697  Train_loss: 0.05089422  Valid_loss:0.00180543 \n",
      "Epoch: 698  Train_loss: 0.05089479  Valid_loss:0.00180287 \n",
      "Epoch: 699  Train_loss: 0.05089221  Valid_loss:0.00180348 \n",
      "Epoch: 700  Train_loss: 0.05089312  Valid_loss:0.00180063 \n",
      "Epoch: 701  Train_loss: 0.05089016  Valid_loss:0.00180162 \n",
      "Epoch: 702  Train_loss: 0.05089159  Valid_loss:0.00179825 \n",
      "Epoch: 703  Train_loss: 0.05088808  Valid_loss:0.00179993 \n",
      "Epoch: 704  Train_loss: 0.05089038  Valid_loss:0.00179572 \n",
      "Epoch: 705  Train_loss: 0.05088565  Valid_loss:0.00179850 \n",
      "Epoch: 706  Train_loss: 0.05088944  Valid_loss:0.00179286 \n",
      "Epoch: 707  Train_loss: 0.05088305  Valid_loss:0.00179743 \n",
      "Epoch: 708  Train_loss: 0.05088914  Valid_loss:0.00178946 \n",
      "Epoch: 709  Train_loss: 0.05087967  Valid_loss:0.00179715 \n",
      "Epoch: 710  Train_loss: 0.05088989  Valid_loss:0.00178511 \n",
      "Epoch: 711  Train_loss: 0.05087513  Valid_loss:0.00179816 \n",
      "Epoch: 712  Train_loss: 0.05089253  Valid_loss:0.00177902 \n",
      "Epoch: 713  Train_loss: 0.05086841  Valid_loss:0.00180159 \n",
      "Epoch: 714  Train_loss: 0.05089891  Valid_loss:0.00176966 \n",
      "Epoch: 715  Train_loss: 0.05085769  Valid_loss:0.00180978 \n",
      "Epoch: 716  Train_loss: 0.05091292  Valid_loss:0.00175389 \n",
      "Epoch: 717  Train_loss: 0.05083985  Valid_loss:0.00182732 \n",
      "Epoch: 718  Train_loss: 0.05094388  Valid_loss:0.00172568 \n",
      "Epoch: 719  Train_loss: 0.05081156  Valid_loss:0.00186406 \n",
      "Epoch: 720  Train_loss: 0.05101660  Valid_loss:0.00167280 \n",
      "Epoch: 721  Train_loss: 0.05077549  Valid_loss:0.00194196 \n",
      "Epoch: 722  Train_loss: 0.05120723  Valid_loss:0.00157152 \n",
      "Epoch: 723  Train_loss: 0.05078335  Valid_loss:0.00211407 \n",
      "Epoch: 724  Train_loss: 0.05178910  Valid_loss:0.00137944 \n",
      "Epoch: 725  Train_loss: 0.05114506  Valid_loss:0.00252463 \n",
      "Epoch: 726  Train_loss: 0.05390513  Valid_loss:0.00104033 \n",
      "Epoch: 727  Train_loss: 0.05338974  Valid_loss:0.00364564 \n",
      "Epoch: 728  Train_loss: 0.06297378  Valid_loss:0.00056214 \n",
      "Epoch: 729  Train_loss: 0.06308294  Valid_loss:0.00713470 \n",
      "Epoch: 730  Train_loss: 0.09897865  Valid_loss:0.00024949 \n",
      "Epoch: 731  Train_loss: 0.06623303  Valid_loss:0.00819002 \n",
      "Epoch: 732  Train_loss: 0.06515418  Valid_loss:0.00049893 \n",
      "Epoch: 733  Train_loss: 0.05085908  Valid_loss:0.00211031 \n",
      "Epoch: 734  Train_loss: 0.05506901  Valid_loss:0.00415385 \n",
      "Epoch: 735  Train_loss: 0.07341746  Valid_loss:0.00036215 \n",
      "Epoch: 736  Train_loss: 0.05576266  Valid_loss:0.00434710 \n",
      "Epoch: 737  Train_loss: 0.05098806  Valid_loss:0.00167835 \n",
      "Epoch: 738  Train_loss: 0.05724924  Valid_loss:0.00074411 \n",
      "Epoch: 739  Train_loss: 0.05554648  Valid_loss:0.00419277 \n",
      "Epoch: 740  Train_loss: 0.05505626  Valid_loss:0.00087869 \n",
      "Epoch: 741  Train_loss: 0.05134173  Valid_loss:0.00146522 \n",
      "Epoch: 742  Train_loss: 0.05364860  Valid_loss:0.00344108 \n",
      "Epoch: 743  Train_loss: 0.05817784  Valid_loss:0.00068417 \n",
      "Epoch: 744  Train_loss: 0.05105340  Valid_loss:0.00208898 \n",
      "Epoch: 745  Train_loss: 0.05216311  Valid_loss:0.00278283 \n",
      "Epoch: 746  Train_loss: 0.05791916  Valid_loss:0.00069082 \n",
      "Epoch: 747  Train_loss: 0.05144507  Valid_loss:0.00237958 \n",
      "Epoch: 748  Train_loss: 0.05134973  Valid_loss:0.00230818 \n",
      "Epoch: 749  Train_loss: 0.05614713  Valid_loss:0.00078344 \n",
      "Epoch: 750  Train_loss: 0.05155955  Valid_loss:0.00243267 \n",
      "Epoch: 751  Train_loss: 0.05102935  Valid_loss:0.00198295 \n",
      "Epoch: 752  Train_loss: 0.05438226  Valid_loss:0.00091481 \n",
      "Epoch: 753  Train_loss: 0.05149353  Valid_loss:0.00238492 \n",
      "Epoch: 754  Train_loss: 0.05099257  Valid_loss:0.00175980 \n",
      "Epoch: 755  Train_loss: 0.05306995  Valid_loss:0.00106050 \n",
      "Epoch: 756  Train_loss: 0.05137416  Valid_loss:0.00230853 \n",
      "Epoch: 757  Train_loss: 0.05109699  Valid_loss:0.00160520 \n",
      "Epoch: 758  Train_loss: 0.05219574  Valid_loss:0.00120674 \n",
      "Epoch: 759  Train_loss: 0.05125304  Valid_loss:0.00222928 \n",
      "Epoch: 760  Train_loss: 0.05125406  Valid_loss:0.00149908 \n",
      "Epoch: 761  Train_loss: 0.05164232  Valid_loss:0.00134614 \n",
      "Epoch: 762  Train_loss: 0.05114319  Valid_loss:0.00215181 \n",
      "Epoch: 763  Train_loss: 0.05140555  Valid_loss:0.00143023 \n",
      "Epoch: 764  Train_loss: 0.05130417  Valid_loss:0.00147455 \n",
      "Epoch: 765  Train_loss: 0.05104841  Valid_loss:0.00207434 \n",
      "Epoch: 766  Train_loss: 0.05151290  Valid_loss:0.00139214 \n",
      "Epoch: 767  Train_loss: 0.05110496  Valid_loss:0.00158916 \n",
      "Epoch: 768  Train_loss: 0.05097294  Valid_loss:0.00199479 \n",
      "Epoch: 769  Train_loss: 0.05155449  Valid_loss:0.00138078 \n",
      "Epoch: 770  Train_loss: 0.05099250  Valid_loss:0.00168745 \n",
      "Epoch: 771  Train_loss: 0.05092353  Valid_loss:0.00191293 \n",
      "Epoch: 772  Train_loss: 0.05152597  Valid_loss:0.00139312 \n",
      "Epoch: 773  Train_loss: 0.05093174  Valid_loss:0.00176694 \n",
      "Epoch: 774  Train_loss: 0.05090671  Valid_loss:0.00183120 \n",
      "Epoch: 775  Train_loss: 0.05143785  Valid_loss:0.00142650 \n",
      "Epoch: 776  Train_loss: 0.05089891  Valid_loss:0.00182479 \n",
      "Epoch: 777  Train_loss: 0.05092443  Valid_loss:0.00175393 \n",
      "Epoch: 778  Train_loss: 0.05131355  Valid_loss:0.00147721 \n",
      "Epoch: 779  Train_loss: 0.05087886  Valid_loss:0.00185927 \n",
      "Epoch: 780  Train_loss: 0.05096963  Valid_loss:0.00168657 \n",
      "Epoch: 781  Train_loss: 0.05117951  Valid_loss:0.00154070 \n",
      "Epoch: 782  Train_loss: 0.05086425  Valid_loss:0.00186950 \n",
      "Epoch: 783  Train_loss: 0.05102567  Valid_loss:0.00163453 \n",
      "Epoch: 784  Train_loss: 0.05105866  Valid_loss:0.00161075 \n",
      "Epoch: 785  Train_loss: 0.05085450  Valid_loss:0.00185662 \n",
      "Epoch: 786  Train_loss: 0.05107056  Valid_loss:0.00160237 \n",
      "Epoch: 787  Train_loss: 0.05096494  Valid_loss:0.00167980 \n",
      "Epoch: 788  Train_loss: 0.05085438  Valid_loss:0.00182483 \n",
      "Epoch: 789  Train_loss: 0.05108566  Valid_loss:0.00159241 \n",
      "Epoch: 790  Train_loss: 0.05090167  Valid_loss:0.00173938 \n",
      "Epoch: 791  Train_loss: 0.05086901  Valid_loss:0.00178119 \n",
      "Epoch: 792  Train_loss: 0.05106464  Valid_loss:0.00160427 \n",
      "Epoch: 793  Train_loss: 0.05086422  Valid_loss:0.00178187 \n",
      "Epoch: 794  Train_loss: 0.05089841  Valid_loss:0.00173491 \n",
      "Epoch: 795  Train_loss: 0.05101566  Valid_loss:0.00163435 \n",
      "Epoch: 796  Train_loss: 0.05084547  Valid_loss:0.00180228 \n",
      "Epoch: 797  Train_loss: 0.05093388  Valid_loss:0.00169559 \n",
      "Epoch: 798  Train_loss: 0.05095632  Valid_loss:0.00167575 \n",
      "Epoch: 799  Train_loss: 0.05084102  Valid_loss:0.00179995 \n",
      "Epoch: 800  Train_loss: 0.05096034  Valid_loss:0.00167095 \n",
      "Epoch: 801  Train_loss: 0.05090335  Valid_loss:0.00171914 \n",
      "Epoch: 802  Train_loss: 0.05084958  Valid_loss:0.00177928 \n",
      "Epoch: 803  Train_loss: 0.05096512  Valid_loss:0.00166497 \n",
      "Epoch: 804  Train_loss: 0.05086611  Valid_loss:0.00175450 \n",
      "Epoch: 805  Train_loss: 0.05086960  Valid_loss:0.00174891 \n",
      "Epoch: 806  Train_loss: 0.05094610  Valid_loss:0.00167709 \n",
      "Epoch: 807  Train_loss: 0.05084617  Valid_loss:0.00177400 \n",
      "Epoch: 808  Train_loss: 0.05089442  Valid_loss:0.00171941 \n",
      "Epoch: 809  Train_loss: 0.05091280  Valid_loss:0.00170167 \n",
      "Epoch: 810  Train_loss: 0.05084163  Valid_loss:0.00177480 \n",
      "Epoch: 811  Train_loss: 0.05091267  Valid_loss:0.00169987 \n",
      "Epoch: 812  Train_loss: 0.05087902  Valid_loss:0.00172982 \n",
      "Epoch: 813  Train_loss: 0.05084989  Valid_loss:0.00176001 \n",
      "Epoch: 814  Train_loss: 0.05091476  Valid_loss:0.00169526 \n",
      "Epoch: 815  Train_loss: 0.05085489  Valid_loss:0.00175161 \n",
      "Epoch: 816  Train_loss: 0.05086647  Valid_loss:0.00173788 \n",
      "Epoch: 817  Train_loss: 0.05090019  Valid_loss:0.00170491 \n",
      "Epoch: 818  Train_loss: 0.05084405  Valid_loss:0.00176020 \n",
      "Epoch: 819  Train_loss: 0.05088325  Valid_loss:0.00171821 \n",
      "Epoch: 820  Train_loss: 0.05087743  Valid_loss:0.00172270 \n",
      "Epoch: 821  Train_loss: 0.05084585  Valid_loss:0.00175441 \n",
      "Epoch: 822  Train_loss: 0.05089066  Valid_loss:0.00170850 \n",
      "Epoch: 823  Train_loss: 0.05085718  Valid_loss:0.00173972 \n",
      "Epoch: 824  Train_loss: 0.05085664  Valid_loss:0.00173925 \n",
      "Epoch: 825  Train_loss: 0.05088466  Valid_loss:0.00171095 \n",
      "Epoch: 826  Train_loss: 0.05084631  Valid_loss:0.00174815 \n",
      "Epoch: 827  Train_loss: 0.05086945  Valid_loss:0.00172326 \n",
      "Epoch: 828  Train_loss: 0.05086977  Valid_loss:0.00172190 \n",
      "Epoch: 829  Train_loss: 0.05084610  Valid_loss:0.00174508 \n",
      "Epoch: 830  Train_loss: 0.05087600  Valid_loss:0.00171406 \n",
      "Epoch: 831  Train_loss: 0.05085482  Valid_loss:0.00173372 \n",
      "Epoch: 832  Train_loss: 0.05085374  Valid_loss:0.00173378 \n",
      "Epoch: 833  Train_loss: 0.05087223  Valid_loss:0.00171458 \n",
      "Epoch: 834  Train_loss: 0.05084651  Valid_loss:0.00173922 \n",
      "Epoch: 835  Train_loss: 0.05086287  Valid_loss:0.00172144 \n",
      "Epoch: 836  Train_loss: 0.05086131  Valid_loss:0.00172195 \n",
      "Epoch: 837  Train_loss: 0.05084676  Valid_loss:0.00173570 \n",
      "Epoch: 838  Train_loss: 0.05086669  Valid_loss:0.00171475 \n",
      "Epoch: 839  Train_loss: 0.05085057  Valid_loss:0.00172964 \n",
      "Epoch: 840  Train_loss: 0.05085287  Valid_loss:0.00172625 \n",
      "Epoch: 841  Train_loss: 0.05086242  Valid_loss:0.00171582 \n",
      "Epoch: 842  Train_loss: 0.05084556  Valid_loss:0.00173169 \n",
      "Epoch: 843  Train_loss: 0.05085889  Valid_loss:0.00171721 \n",
      "Epoch: 844  Train_loss: 0.05085357  Valid_loss:0.00172134 \n",
      "Epoch: 845  Train_loss: 0.05084717  Valid_loss:0.00172679 \n",
      "Epoch: 846  Train_loss: 0.05085939  Valid_loss:0.00171362 \n",
      "Epoch: 847  Train_loss: 0.05084639  Valid_loss:0.00172550 \n",
      "Epoch: 848  Train_loss: 0.05085199  Valid_loss:0.00171875 \n",
      "Epoch: 849  Train_loss: 0.05085390  Valid_loss:0.00171577 \n",
      "Epoch: 850  Train_loss: 0.05084447  Valid_loss:0.00172425 \n",
      "Epoch: 851  Train_loss: 0.05085463  Valid_loss:0.00171299 \n",
      "Epoch: 852  Train_loss: 0.05084687  Valid_loss:0.00171963 \n",
      "Epoch: 853  Train_loss: 0.05084703  Valid_loss:0.00171843 \n",
      "Epoch: 854  Train_loss: 0.05085208  Valid_loss:0.00171235 \n",
      "Epoch: 855  Train_loss: 0.05084290  Valid_loss:0.00172039 \n",
      "Epoch: 856  Train_loss: 0.05084975  Valid_loss:0.00171244 \n",
      "Epoch: 857  Train_loss: 0.05084617  Valid_loss:0.00171492 \n",
      "Epoch: 858  Train_loss: 0.05084326  Valid_loss:0.00171671 \n",
      "Epoch: 859  Train_loss: 0.05084920  Valid_loss:0.00170975 \n",
      "Epoch: 860  Train_loss: 0.05084122  Valid_loss:0.00171658 \n",
      "Epoch: 861  Train_loss: 0.05084552  Valid_loss:0.00171118 \n",
      "Epoch: 862  Train_loss: 0.05084428  Valid_loss:0.00171128 \n",
      "Epoch: 863  Train_loss: 0.05084012  Valid_loss:0.00171434 \n",
      "Epoch: 864  Train_loss: 0.05084527  Valid_loss:0.00170811 \n",
      "Epoch: 865  Train_loss: 0.05083917  Valid_loss:0.00171302 \n",
      "Epoch: 866  Train_loss: 0.05084122  Valid_loss:0.00170976 \n",
      "Epoch: 867  Train_loss: 0.05084126  Valid_loss:0.00170863 \n",
      "Epoch: 868  Train_loss: 0.05083694  Valid_loss:0.00171171 \n",
      "Epoch: 869  Train_loss: 0.05084085  Valid_loss:0.00170660 \n",
      "Epoch: 870  Train_loss: 0.05083627  Valid_loss:0.00171004 \n",
      "Epoch: 871  Train_loss: 0.05083699  Valid_loss:0.00170805 \n",
      "Epoch: 872  Train_loss: 0.05083736  Valid_loss:0.00170652 \n",
      "Epoch: 873  Train_loss: 0.05083334  Valid_loss:0.00170925 \n",
      "Epoch: 874  Train_loss: 0.05083614  Valid_loss:0.00170513 \n",
      "Epoch: 875  Train_loss: 0.05083242  Valid_loss:0.00170760 \n",
      "Epoch: 876  Train_loss: 0.05083250  Valid_loss:0.00170624 \n",
      "Epoch: 877  Train_loss: 0.05083268  Valid_loss:0.00170476 \n",
      "Epoch: 878  Train_loss: 0.05082908  Valid_loss:0.00170701 \n",
      "Epoch: 879  Train_loss: 0.05083106  Valid_loss:0.00170364 \n",
      "Epoch: 880  Train_loss: 0.05082769  Valid_loss:0.00170561 \n",
      "Epoch: 881  Train_loss: 0.05082745  Valid_loss:0.00170447 \n",
      "Epoch: 882  Train_loss: 0.05082708  Valid_loss:0.00170339 \n",
      "Epoch: 883  Train_loss: 0.05082302  Valid_loss:0.00170526 \n",
      "Epoch: 884  Train_loss: 0.05082323  Valid_loss:0.00170257 \n",
      "Epoch: 885  Train_loss: 0.05081873  Valid_loss:0.00170446 \n",
      "Epoch: 886  Train_loss: 0.05081682  Valid_loss:0.00170348 \n",
      "Epoch: 887  Train_loss: 0.05081417  Valid_loss:0.00170301 \n",
      "Epoch: 888  Train_loss: 0.05080940  Valid_loss:0.00170449 \n",
      "Epoch: 889  Train_loss: 0.05080763  Valid_loss:0.00170267 \n",
      "Epoch: 890  Train_loss: 0.05080190  Valid_loss:0.00170455 \n",
      "Epoch: 891  Train_loss: 0.05079862  Valid_loss:0.00170372 \n",
      "Epoch: 892  Train_loss: 0.05079938  Valid_loss:0.00170407 \n",
      "Epoch: 893  Train_loss: 0.05080247  Valid_loss:0.00170283 \n",
      "Epoch: 894  Train_loss: 0.05079368  Valid_loss:0.00170453 \n",
      "Epoch: 895  Train_loss: 0.05079506  Valid_loss:0.00170149 \n",
      "Epoch: 896  Train_loss: 0.05079164  Valid_loss:0.00170569 \n",
      "Epoch: 897  Train_loss: 0.05079729  Valid_loss:0.00170030 \n",
      "Epoch: 898  Train_loss: 0.05079279  Valid_loss:0.00170432 \n",
      "Epoch: 899  Train_loss: 0.05079399  Valid_loss:0.00170205 \n",
      "Epoch: 900  Train_loss: 0.05079249  Valid_loss:0.00170181 \n",
      "Epoch: 901  Train_loss: 0.05078775  Valid_loss:0.00170426 \n",
      "Epoch: 902  Train_loss: 0.05078828  Valid_loss:0.00170077 \n",
      "Epoch: 903  Train_loss: 0.05078060  Valid_loss:0.00170490 \n",
      "Epoch: 904  Train_loss: 0.05077924  Valid_loss:0.00170209 \n",
      "Epoch: 905  Train_loss: 0.05077245  Valid_loss:0.00170415 \n",
      "Epoch: 906  Train_loss: 0.05078514  Valid_loss:0.00170472 \n",
      "Epoch: 907  Train_loss: 0.05078794  Valid_loss:0.00169960 \n",
      "Epoch: 908  Train_loss: 0.05076453  Valid_loss:0.00170722 \n",
      "Epoch: 909  Train_loss: 0.05077111  Valid_loss:0.00170152 \n",
      "Epoch: 910  Train_loss: 0.05076947  Valid_loss:0.00170308 \n",
      "Epoch: 911  Train_loss: 0.05076628  Valid_loss:0.00170499 \n",
      "Epoch: 912  Train_loss: 0.05076874  Valid_loss:0.00170024 \n",
      "Epoch: 913  Train_loss: 0.05075884  Valid_loss:0.00170681 \n",
      "Epoch: 914  Train_loss: 0.05076072  Valid_loss:0.00170066 \n",
      "Epoch: 915  Train_loss: 0.05076465  Valid_loss:0.00170640 \n",
      "Epoch: 916  Train_loss: 0.05076427  Valid_loss:0.00169761 \n",
      "Epoch: 917  Train_loss: 0.05075540  Valid_loss:0.00170582 \n",
      "Epoch: 918  Train_loss: 0.05076129  Valid_loss:0.00170331 \n",
      "Epoch: 919  Train_loss: 0.05076830  Valid_loss:0.00169804 \n",
      "Epoch: 920  Train_loss: 0.05075864  Valid_loss:0.00170790 \n",
      "Epoch: 921  Train_loss: 0.05077054  Valid_loss:0.00169466 \n",
      "Epoch: 922  Train_loss: 0.05075400  Valid_loss:0.00170837 \n",
      "Epoch: 923  Train_loss: 0.05076150  Valid_loss:0.00169659 \n",
      "Epoch: 924  Train_loss: 0.05074692  Valid_loss:0.00170545 \n",
      "Epoch: 925  Train_loss: 0.05074367  Valid_loss:0.00170173 \n",
      "Epoch: 926  Train_loss: 0.05075104  Valid_loss:0.00170190 \n",
      "Epoch: 927  Train_loss: 0.05074845  Valid_loss:0.00169827 \n",
      "Epoch: 928  Train_loss: 0.05074062  Valid_loss:0.00170273 \n",
      "Epoch: 929  Train_loss: 0.05074421  Valid_loss:0.00170340 \n",
      "Epoch: 930  Train_loss: 0.05075452  Valid_loss:0.00169516 \n",
      "Epoch: 931  Train_loss: 0.05074245  Valid_loss:0.00170713 \n",
      "Epoch: 932  Train_loss: 0.05075538  Valid_loss:0.00169201 \n",
      "Epoch: 933  Train_loss: 0.05073533  Valid_loss:0.00170781 \n",
      "Epoch: 934  Train_loss: 0.05074358  Valid_loss:0.00169339 \n",
      "Epoch: 935  Train_loss: 0.05072300  Valid_loss:0.00170608 \n",
      "Epoch: 936  Train_loss: 0.05074455  Valid_loss:0.00169799 \n",
      "Epoch: 937  Train_loss: 0.05074058  Valid_loss:0.00169221 \n",
      "Epoch: 938  Train_loss: 0.05072241  Valid_loss:0.00170729 \n",
      "Epoch: 939  Train_loss: 0.05074466  Valid_loss:0.00169154 \n",
      "Epoch: 940  Train_loss: 0.05073733  Valid_loss:0.00170239 \n",
      "Epoch: 941  Train_loss: 0.05074617  Valid_loss:0.00169419 \n",
      "Epoch: 942  Train_loss: 0.05074058  Valid_loss:0.00169758 \n",
      "Epoch: 943  Train_loss: 0.05073560  Valid_loss:0.00169788 \n",
      "Epoch: 944  Train_loss: 0.05073200  Valid_loss:0.00169431 \n",
      "Epoch: 945  Train_loss: 0.05071540  Valid_loss:0.00170157 \n",
      "Epoch: 946  Train_loss: 0.05072641  Valid_loss:0.00169296 \n",
      "Epoch: 947  Train_loss: 0.05071704  Valid_loss:0.00169031 \n",
      "Epoch: 948  Train_loss: 0.05071952  Valid_loss:0.00169957 \n",
      "Epoch: 949  Train_loss: 0.05073398  Valid_loss:0.00169377 \n",
      "Epoch: 950  Train_loss: 0.05074139  Valid_loss:0.00169117 \n",
      "Epoch: 951  Train_loss: 0.05073613  Valid_loss:0.00169772 \n",
      "Epoch: 952  Train_loss: 0.05074615  Valid_loss:0.00168545 \n",
      "Epoch: 953  Train_loss: 0.05072454  Valid_loss:0.00170162 \n",
      "Epoch: 954  Train_loss: 0.05073559  Valid_loss:0.00168213 \n",
      "Epoch: 955  Train_loss: 0.05070095  Valid_loss:0.00170557 \n",
      "Epoch: 956  Train_loss: 0.05071411  Valid_loss:0.00168086 \n",
      "Epoch: 957  Train_loss: 0.05070291  Valid_loss:0.00169080 \n",
      "Epoch: 958  Train_loss: 0.05068202  Valid_loss:0.00171015 \n",
      "Epoch: 959  Train_loss: 0.05073734  Valid_loss:0.00166351 \n",
      "Epoch: 960  Train_loss: 0.05068013  Valid_loss:0.00171659 \n",
      "Epoch: 961  Train_loss: 0.05073045  Valid_loss:0.00167073 \n",
      "Epoch: 962  Train_loss: 0.05069401  Valid_loss:0.00170736 \n",
      "Epoch: 963  Train_loss: 0.05072163  Valid_loss:0.00167593 \n",
      "Epoch: 964  Train_loss: 0.05068671  Valid_loss:0.00170332 \n",
      "Epoch: 965  Train_loss: 0.05069992  Valid_loss:0.00167962 \n",
      "Epoch: 966  Train_loss: 0.05070474  Valid_loss:0.00168079 \n",
      "Epoch: 967  Train_loss: 0.05067119  Valid_loss:0.00171821 \n",
      "Epoch: 968  Train_loss: 0.05074813  Valid_loss:0.00164242 \n",
      "Epoch: 969  Train_loss: 0.05063138  Valid_loss:0.00175822 \n",
      "Epoch: 970  Train_loss: 0.05080777  Valid_loss:0.00160233 \n",
      "Epoch: 971  Train_loss: 0.05061267  Valid_loss:0.00178659 \n",
      "Epoch: 972  Train_loss: 0.05082534  Valid_loss:0.00158406 \n",
      "Epoch: 973  Train_loss: 0.05060009  Valid_loss:0.00181915 \n",
      "Epoch: 974  Train_loss: 0.05089524  Valid_loss:0.00153966 \n",
      "Epoch: 975  Train_loss: 0.05060363  Valid_loss:0.00189366 \n",
      "Epoch: 976  Train_loss: 0.05113147  Valid_loss:0.00143707 \n",
      "Epoch: 977  Train_loss: 0.05064094  Valid_loss:0.00208582 \n",
      "Epoch: 978  Train_loss: 0.05177512  Valid_loss:0.00125906 \n",
      "Epoch: 979  Train_loss: 0.05103990  Valid_loss:0.00245494 \n",
      "Epoch: 980  Train_loss: 0.05369243  Valid_loss:0.00097806 \n",
      "Epoch: 981  Train_loss: 0.05288876  Valid_loss:0.00334354 \n",
      "Epoch: 982  Train_loss: 0.06004337  Valid_loss:0.00060089 \n",
      "Epoch: 983  Train_loss: 0.05905752  Valid_loss:0.00555288 \n",
      "Epoch: 984  Train_loss: 0.08042285  Valid_loss:0.00027112 \n",
      "Epoch: 985  Train_loss: 0.06742843  Valid_loss:0.00840387 \n",
      "Epoch: 986  Train_loss: 0.08807290  Valid_loss:0.00022774 \n",
      "Epoch: 987  Train_loss: 0.05594636  Valid_loss:0.00434246 \n",
      "Epoch: 988  Train_loss: 0.05093122  Valid_loss:0.00209127 \n",
      "Epoch: 989  Train_loss: 0.06331740  Valid_loss:0.00048695 \n",
      "Epoch: 990  Train_loss: 0.06013303  Valid_loss:0.00567488 \n",
      "Epoch: 991  Train_loss: 0.06325921  Valid_loss:0.00047928 \n",
      "Epoch: 992  Train_loss: 0.05089802  Valid_loss:0.00204810 \n",
      "Epoch: 993  Train_loss: 0.05382397  Valid_loss:0.00340502 \n",
      "Epoch: 994  Train_loss: 0.06628383  Valid_loss:0.00040768 \n",
      "Epoch: 995  Train_loss: 0.05352462  Valid_loss:0.00324373 \n",
      "Epoch: 996  Train_loss: 0.05090247  Valid_loss:0.00189779 \n",
      "Epoch: 997  Train_loss: 0.05794767  Valid_loss:0.00063260 \n",
      "Epoch: 998  Train_loss: 0.05382627  Valid_loss:0.00329437 \n",
      "Epoch: 999  Train_loss: 0.05174506  Valid_loss:0.00120478 \n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_correct = []\n",
    "valid_correct = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    out1 = Model.forward(Xtrain)\n",
    "    train_loss = criterion(out1, Ytrain)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    out2 = Model.forward(xvalid)\n",
    "    valid_loss = criterion(out2, yvalid)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    #print(\"Epoch {epoch:2}, Loss = {loss.item():10.8f}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    valid_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #train_correct += (out1 == Ytrain).float().sum()\n",
    "    #valid_correct += (out2 == yvalid).float().sum()\n",
    "    \n",
    "    print(f'Epoch: {epoch:2}  Train_loss: {train_loss.item():10.8f}  Valid_loss:{valid_loss.item():10.8f} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), train_losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), valid_losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_out = Model(xtest)\n",
    "_, predict_y = torch.max(predict_out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 2, 0, 2, 1, 2, 2, 1, 2, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 2, 1, 0,\n",
       "        1, 2, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "print('prediction accuracy :', accuracy_score(ytest.data, predict_y.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

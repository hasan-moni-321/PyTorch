{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using torch.tensor\n",
    "t = torch.Tensor([[1,2,3], [3,4,5]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5975,  0.2973, -0.7316, -0.5976,  0.7884],\n",
       "        [-1.7344, -0.4889, -0.2703, -0.0820, -0.2320],\n",
       "        [-1.3007, -1.0921,  0.9187,  0.0962, -0.7346]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using torch.randn\n",
    "t = torch.randn(3,5)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using torch.ones\n",
    "t = torch.ones(3,5)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using torch.zeros\n",
    "t = torch.zeros(3,5)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4, 4, 0, 3],\n",
       "        [3, 0, 3, 2, 2],\n",
       "        [4, 0, 2, 3, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using torch.randn\n",
    "t = torch.randint(low=0, high=5, size=(3,5))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor from numpy array\n",
    "a = np.array([[1,2,3], [4,5,6]])\n",
    "t = torch.from_numpy(a)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy from tensor\n",
    "a = t.numpy()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4942,  1.1303],\n",
       "        [-0.0312, -2.3750],\n",
       "        [ 0.2509, -0.9964]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(3,4)\n",
    "W = torch.randn(4,2)\n",
    "\n",
    "#multiply matrix A, W\n",
    "t = A.mm(W)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4942, -0.0312,  0.2509],\n",
       "        [ 1.1303, -2.3750, -0.9964]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose tensor\n",
    "t = t.t()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4420e-01, 9.7348e-04, 6.2955e-02],\n",
       "        [1.2775e+00, 5.6407e+00, 9.9280e-01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# square each element of t\n",
    "t = t**2\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the t\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to define nerural network in PyTorch\n",
    "class myNueralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define all the layers here\n",
    "        self.lin1 = nn.Linear(784, 30)\n",
    "        self.lin2 = nn.Linear(30, 30)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the thing to note is that we can define any sort of calculation while defining the forward pass, and that makes PyTorch highly customizable for research purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCrazyNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #define all the layers\n",
    "        self.lin1 = nn.Linear(784, 30)\n",
    "        self.lin2 = nn.Linear(30, 784)\n",
    "        self.lin3 = nn.Linear(30, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # connection of the layers\n",
    "        x_lin1 = self.lin1(x)\n",
    "        x_lin2 = x + self.lin2(x_lin1)\n",
    "        x_lin2 = self.lin1(x_lin2)\n",
    "        x = self.lin3(x_lin2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((100, 784))\n",
    "model = myCrazyNeuralNet()\n",
    "#model(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining custom linear layers\n",
    "class myCustomLinearLayer(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(in_size, out_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_size))\n",
    "    \n",
    "    # connect custom layer    \n",
    "    def forward(self, x):\n",
    "        return x.mm(self.weights) + self.bias\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myCustomNeuralnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Calling custom layer\n",
    "        self.lin1 = myCustomLinearLayer(784, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # connect the layer\n",
    "        x = self.lin1(x)\n",
    "        return x\n",
    "    \n",
    "x = torch.randn(100, 784)\n",
    "model = myCustomNeuralnet()\n",
    "model(x).size()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3,3), stride=1, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 64, 24, 24])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((100, 3, 24,24))\n",
    "conv_layer(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of image in the dataset : 5360\n",
      "Example image and label : (tensor([[[0.5137, 0.5098, 0.5098,  ..., 0.8353, 0.8353, 0.8314],\n",
      "         [0.5176, 0.5176, 0.5137,  ..., 0.8549, 0.8314, 0.8235],\n",
      "         [0.5216, 0.5176, 0.5176,  ..., 0.8706, 0.8392, 0.8314],\n",
      "         ...,\n",
      "         [0.6157, 0.6196, 0.6118,  ..., 0.5647, 0.5725, 0.5569],\n",
      "         [0.6157, 0.6235, 0.6275,  ..., 0.5725, 0.5804, 0.5686],\n",
      "         [0.6118, 0.6353, 0.6392,  ..., 0.5725, 0.5765, 0.5686]],\n",
      "\n",
      "        [[0.4392, 0.4353, 0.4392,  ..., 0.6510, 0.6471, 0.6353],\n",
      "         [0.4471, 0.4471, 0.4431,  ..., 0.6863, 0.6549, 0.6431],\n",
      "         [0.4510, 0.4471, 0.4431,  ..., 0.7216, 0.6863, 0.6627],\n",
      "         ...,\n",
      "         [0.5059, 0.5059, 0.4824,  ..., 0.4275, 0.4353, 0.4196],\n",
      "         [0.5059, 0.5137, 0.5098,  ..., 0.4353, 0.4431, 0.4314],\n",
      "         [0.4941, 0.5176, 0.5137,  ..., 0.4392, 0.4392, 0.4314]],\n",
      "\n",
      "        [[0.3098, 0.3059, 0.3059,  ..., 0.5843, 0.5647, 0.5412],\n",
      "         [0.3098, 0.3098, 0.2980,  ..., 0.6353, 0.5843, 0.5608],\n",
      "         [0.3098, 0.3020, 0.2902,  ..., 0.6706, 0.6118, 0.5765],\n",
      "         ...,\n",
      "         [0.3529, 0.3529, 0.3451,  ..., 0.3176, 0.3255, 0.3098],\n",
      "         [0.3529, 0.3608, 0.3647,  ..., 0.3255, 0.3333, 0.3216],\n",
      "         [0.3529, 0.3765, 0.3725,  ..., 0.3294, 0.3294, 0.3216]]]), 0)\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/home/hasan/DATA SET/Indoor CVPR/train_image\"\n",
    "\n",
    "t = transforms.Compose([\n",
    "                    transforms.Resize(size=256),\n",
    "                    transforms.CenterCrop(size=224),\n",
    "                    transforms.ToTensor()\n",
    "                    ])\n",
    "\n",
    "train_dataset = ImageFolder(root=train_path, transform=t)\n",
    "\n",
    "print(\"Total number of image in the dataset :\", len(train_dataset))\n",
    "print(\"Example image and label :\", train_dataset[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 5360 images, and we can get an image and its label using an index. Now we can pass images one by one to any image neural network using a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(train_dataset)):\n",
    "    image, label = train_dataset[i]\n",
    "    pred = model(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that is not optimal. We want to do batching and using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 224, 224]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in train_dataloader:\n",
    "    print(image_batch.size(), label_batch.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The whole process of dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/home/hasan/DATA SET/Indoor CVPR/train_image\"\n",
    "\n",
    "t = transforms.Compose([\n",
    "                    transforms.Resize(size=256),\n",
    "                    transforms.CenterCrop(size=224),\n",
    "                    transforms.ToTensor()\n",
    "                    ])\n",
    "\n",
    "train_dataset = ImageFolder(root=train_path, transform=t)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=10)\n",
    "\n",
    "for image_batch, label_batch in train_dataloader:\n",
    "    pred = myImageNeuralNet(image_batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the main power of Pytorch comes with its immense customization. We can also create our own custom datasets if the datasets provided by PyTorch don’t fit our use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Custom Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customImageFolderDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        \n",
    "        self.image_paths = glob(f\"{root}/*/*\")\n",
    "        \n",
    "        self.labels = [x.split(\"/\")[-2] for x in self.image_paths]\n",
    "        \n",
    "        self.label_to_idx = {x:i for i,x in enumerate(set(self.labels))}\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        # return length of dataset\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # open and send one image and label\n",
    "        img_name = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.label_to_idx[label]\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/home/hasan/DATA SET/Indoor CVPR/train_image\"\n",
    "\n",
    "t = transforms.Compose([\n",
    "                    transforms.Resize(size=256),\n",
    "                    transforms.CenterCrop(size=224),\n",
    "                    transforms.ToTensor()\n",
    "                    ])\n",
    "\n",
    "train_dataset = customImageFolderDataset(root=train_path, transform=t)\n",
    "train_dataloader = DataLoader(train_dataset,batch_size = 64, shuffle=True, num_workers=10)\n",
    "\n",
    "for image_batch, label_batch in train_dataloader:\n",
    "    pred = myImageNeuralNet(image_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Custom DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know how to create a neural network using nn.Module. But how to train it? Any neural network that has to be trained will have a training loop that will look something similar to below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #set model to train mode\n",
    "    model.train()\n",
    "    for x_batch, y_batch in train_dataloader:\n",
    "        \n",
    "        #clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward pass - predicted output\n",
    "        pred = model(x_batch)\n",
    "        \n",
    "        # find loss and backpropagation of gradients\n",
    "        loss= loss_criterion(pred, y_batch)\n",
    "        loss.backward()\n",
    "        \n",
    "        #update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    for x_batch, y_batch in valid_dataloader:\n",
    "        pred = model(x_batch)\n",
    "        val_loss = loss_criterion(pred, y_batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch provides us with a variety of loss functions for our most common tasks, like Classification and Regression. Some most used examples are "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. nn.CrossEntropyLoss , \n",
    "2. nn.NLLLoss , \n",
    "3. nn.KLDivLoss and \n",
    "4. nn.MSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can try to use this Loss function for a simple classification network. Please note the LogSoftmax layer after the final linear layer. If you don't want to use this LogSoftmax layer, you could have just used nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myClassificationNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define all Layers Here\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        # Connect the layer Outputs here to define the forward pass\n",
    "        x = self.lin(x)\n",
    "        x = self.logsoftmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some random input:\n",
    "X = torch.randn(100,784)\n",
    "y = torch.randint(low = 0,high = 10,size = (100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 7, 7, 0, 7, 5, 3, 5, 5, 0, 9, 7, 6, 1, 9, 9, 0, 8, 5, 3, 3, 4, 9,\n",
       "        9, 8, 7, 1, 3, 0, 2, 7, 7, 5, 5, 7, 3, 1, 1, 7, 0, 7, 3, 2, 3, 2, 6, 6,\n",
       "        6, 6, 0, 4, 4, 7, 6, 4, 5, 5, 8, 7, 5, 3, 4, 1, 6, 1, 4, 8, 6, 0, 0, 5,\n",
       "        1, 1, 3, 8, 1, 4, 0, 7, 0, 0, 6, 1, 4, 6, 0, 2, 6, 0, 9, 6, 9, 7, 7, 4,\n",
       "        1, 6, 8, 7])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And pass it through the model to get predictions:\n",
    "model = myClassificationNet()\n",
    "preds = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4575, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can now get the loss as:\n",
    "criterion = nn.NLLLoss()\n",
    "loss = criterion(preds,y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining your custom loss functions is again a piece of cake, and you should be okay as long as you use tensor operations in your loss function. For example, here is the customMseLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customMseLoss(output, target):\n",
    "    loss = torch.mean((output - target)**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this custom loss just like before. But note that we don’t instantiate the loss using criterion this time as we have defined it as a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(X)\n",
    "loss = customMseLoss(output, target)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted, we could have also written it as a class using nn.Module , and then we would have been able to use it as an object. Here is an NLLLoss custom example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNLLLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x, y):\n",
    "        # x should be output from LogSoftmax Layer \n",
    "        log_prob = -1.0 * x\n",
    "        # Get log_prob based on y class_index as loss=-mean(ylogp)\n",
    "        loss = log_prob.gather(1, y.unsqueeze(1))\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "criterion = CustomNLLLoss()\n",
    "loss = criterion(preds,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we get gradients using the loss.backward() call, we need to take an optimizer step to change the weights in the whole network. Pytorch provides a variety of different ready to use optimizers using the torch.optim module. For example: \n",
    "1. torch.optim.Adadelta , \n",
    "2. torch.optim.Adagrad , \n",
    "3. torch.optim.RMSprop and the most widely used \n",
    "4. torch.optim.Adam.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use the most used Adam optimizer from PyTorch, we can simply instantiate it with:\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
